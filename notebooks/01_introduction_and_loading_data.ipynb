{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01: Introduction to xsnow and Loading Data\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Austfi/xsnowForPatrol/blob/main/notebooks/01_introduction_and_loading_data.ipynb)\n",
    "\n",
    "This notebook introduces you to xsnow, the Python libraries it builds on, and how to load snowpack data.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- What xsnow is and why it's useful\n",
    "- Python fundamentals: NumPy, pandas, and xarray basics\n",
    "- Understanding xsnow's 5-dimensional data model\n",
    "- How to load .pro and .smet files\n",
    "- Exploring dataset structure and metadata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning objectives\n",
    "- Understand how xsnow represents snowpack data across dimensions.\n",
    "- Practice NumPy, pandas, and xarray operations that underpin xsnow workflows.\n",
    "- Load the sample xsnow dataset and interpret its coordinates and variables.\n",
    "- Inspect metadata to connect measurements to physical meaning.\n",
    "\n",
    "**Prerequisites**\n",
    "- [ ] Ability to run Python code cells in a notebook.\n",
    "- [ ] Comfort with basic Python data structures (lists, dictionaries).\n",
    "- [ ] Prior exposure to NumPy or pandas fundamentals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation (For Colab Users)\n",
    "\n",
    "If you're using Google Colab, run the cell below to install xsnow and dependencies. If you're running locally and have already installed xsnow, you can skip this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run.\n",
    "\n",
    "%pip install -q numpy pandas xarray matplotlib seaborn dask netcdf4\n",
    "%pip install -q git+https://gitlab.com/avacollabra/postprocessing/xsnow\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: What is xsnow?\n",
    "\n",
    "**xsnow** is a Python library designed to make working with snowpack simulation data efficient and intuitive. It's built specifically for data from the SNOWPACK model (and other snow models), which outputs detailed information about snow layers over time.\n",
    "\n",
    "### Why xsnow?\n",
    "\n",
    "- **Handles complex file formats**: SNOWPACK outputs come in specialized formats (.pro, .smet) that xsnow can parse automatically\n",
    "- **Organized data structure**: Instead of juggling hundreds of separate files, xsnow organizes everything into a single, coherent dataset\n",
    "- **Powerful analysis tools**: Built-in functions for common snowpack analyses (SWE, weak layers, stability indices)\n",
    "- **Built on proven libraries**: Uses xarray, NumPy, and pandas under the hood, so you get their full power\n",
    "\n",
    "### The Big Picture\n",
    "\n",
    "Think of xsnow as a translator: it takes raw SNOWPACK output files and converts them into a format that's easy to work with in Python. Instead of manually parsing text files, you get a clean, organized dataset where you can ask questions like \"Show me all weak layers on north-facing slopes after February 1st\" with simple code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Python Fundamentals for xsnow\n",
    "We'll use a show \u2192 run \u2192 explain rhythm so each library demo stays focused.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run.\n",
    "import numpy as np\n",
    "\n",
    "# Create a simple array\n",
    "temperatures = np.array([-5, -3, -1, 0, -2])\n",
    "\n",
    "# Arrays can be multi-dimensional\n",
    "# Imagine 3 layers, each with a temperature\n",
    "layer_temps = np.array([[-5, -3, -1],  # Layer 0 (surface)\n",
    "                        [-3, -2, -1],  # Layer 1\n",
    "                        [-2, -1, 0]])  # Layer 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain.** NumPy arrays let us reason about entire snow layers at once while preserving numeric efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check for understanding: confirm array shapes\n",
    "assert temperatures.shape == (5,)\n",
    "assert layer_temps.shape == (3, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas: Working with Tables\n",
    "**Show.** We'll assemble a tiny table of snow depth observations to see DataFrame basics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run.\n",
    "import pandas as pd\n",
    "\n",
    "# Create a simple table (DataFrame)\n",
    "data = {\n",
    "    'time': ['2024-01-01', '2024-01-02', '2024-01-03'],\n",
    "    'snow_depth': [50, 55, 60],  # cm\n",
    "    'temperature': [-5, -3, -1]   # \u00b0C\n",
    "}\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain.** A pandas DataFrame keeps measurements aligned by column so we can sort, filter, and visualize with ease.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check for understanding: DataFrame columns and units\n",
    "assert list(df.columns) == ['time', 'snow_depth', 'temperature']\n",
    "assert df['snow_depth'].max() == 60\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XArray: Multi-Dimensional Labeled Arrays\n",
    "**Show.** We'll label a 3D temperature block to preview xsnow's multi-indexed style.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run.\n",
    "import xarray as xr\n",
    "\n",
    "# Create a simple xarray DataArray (like a NumPy array with labels)\n",
    "# Let's say we have temperature data for 2 locations, 3 time steps, 2 layers\n",
    "temps = np.array([[[-5, -3],   # Location 0, Time 0, Layers [0, 1]\n",
    "                   [-4, -2],   # Location 0, Time 1\n",
    "                   [-3, -1]],  # Location 0, Time 2\n",
    "                  [[-6, -4],   # Location 1, Time 0\n",
    "                   [-5, -3],   # Location 1, Time 1\n",
    "                   [-4, -2]]]) # Location 1, Time 2\n",
    "\n",
    "# Create labeled dimensions\n",
    "da = xr.DataArray(\n",
    "    temps,\n",
    "    dims=['location', 'time', 'layer'],\n",
    "    coords={\n",
    "        'location': ['Station_A', 'Station_B'],\n",
    "        'time': pd.date_range('2024-01-01', periods=3, freq='D'),\n",
    "        'layer': [0, 1]  # Layer 0 = surface, Layer 1 = deeper\n",
    "    },\n",
    "    name='temperature'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain.** xarray wraps the NumPy array with coordinate labels so xsnow can align measurements across stations, time, and layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check for understanding: labeled access\n",
    "assert da.sel(location='Station_A', layer=0).shape == (3,)\n",
    "assert 'time' in da.coords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key XArray Concepts:**\n",
    "- **Dimensions**: The axes of your data (location, time, layer)\n",
    "- **Coordinates**: Labels for each dimension (e.g., station names, dates)\n",
    "- **DataArray**: A single variable with dimensions (like our temperature above)\n",
    "- **Dataset**: A collection of DataArrays that share dimensions\n",
    "\n",
    "xsnow uses xarray's Dataset structure to organize all snowpack variables together!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Understanding xsnow's Data Model\n",
    "\n",
    "xsnow organizes snowpack data using **5 key dimensions**. This might sound complex, but it's actually very logical once you understand it.\n",
    "\n",
    "### The 5 Dimensions\n",
    "\n",
    "1. **location**: The site or grid point (e.g., \"VIR1A\", \"Station_1\")\n",
    "2. **time**: When the profile was measured/simulated\n",
    "3. **slope**: Different slope aspects at the same location (north-facing, south-facing, etc.)\n",
    "4. **realization**: Different model runs or scenarios (for ensemble runs)\n",
    "5. **layer**: The vertical layers within the snowpack (layer 0 = surface, higher numbers = deeper)\n",
    "\n",
    "### Why This Structure?\n",
    "\n",
    "This structure allows you to ask powerful questions:\n",
    "- \"Show me density profiles for all locations on February 1st\"\n",
    "- \"Compare north vs south-facing slopes\"\n",
    "- \"Find weak layers across all time steps\"\n",
    "- All without writing loops!\n",
    "\n",
    "### Profile-level vs Layer-level Variables\n",
    "\n",
    "- **Profile-level**: Properties of the entire snowpack (e.g., total snow height HS). These don't vary by layer.\n",
    "- **Layer-level**: Properties of individual layers (e.g., density, temperature). These vary by layer.\n",
    "\n",
    "Let's see this in action once we load some data!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Loading Data with xsnow\n",
    "**Show.** We'll call `xsnow.single_profile_timeseries()` to grab a tiny bundled dataset for experimentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run.\n",
    "import xsnow\n",
    "\n",
    "# Load xsnow's lightweight sample time series dataset\n",
    "# This returns an xsnowDataset with a time series of snow profiles\n",
    "print(\"Loading xsnow sample data...\")\n",
    "print(\"Using xsnow.single_profile_timeseries() - a lightweight time series dataset\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    ds = xsnow.single_profile_timeseries()\n",
    "    print(\"\u2705 Data loaded successfully!\")\n",
    "    print(\"\\nDataset summary:\")\n",
    "    print(ds)\n",
    "    print(\"\\nDataset dimensions:\")\n",
    "    print(f\"  {dict(ds.dims)}\")\n",
    "    print(\"\\nDataset coordinates:\")\n",
    "    for coord in ds.coords:\n",
    "        print(f\"  {coord}: {ds.coords[coord].shape}\")\n",
    "    print(\"\\nDataset variables:\")\n",
    "    for var in ds.data_vars:\n",
    "        print(f\"  {var}: {ds[var].dims}\")\n",
    "except Exception as e:\n",
    "    print(f\"\u274c Error loading sample data: {e}\")\n",
    "    print(\"\\nMake sure xsnow is properly installed:\")\n",
    "    print(\"  pip install git+https://gitlab.com/avacollabra/postprocessing/xsnow\")\n",
    "    ds = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain.** The helper returns an `xsnow.Dataset` preloaded with snow profile timelines so you can explore without hunting for files.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check for understanding: dataset availability\n",
    "assert ds is not None, 'Re-run the install cell if the sample dataset failed to load.'\n",
    "assert 'time' in ds.dims\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Dataset Structure\n",
    "**Show.** Let's preview the core dimensions, coordinates, and variables that xsnow tracks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run.\n",
    "if ds is None:\n",
    "    raise RuntimeError('Load the dataset above before inspecting it.')\n",
    "\n",
    "print('Dimensions:', dict(ds.dims))\n",
    "print('Coordinates:', list(ds.coords))\n",
    "print('Variables:', list(ds.data_vars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain.** The printed summary confirms xsnow tracks layers (`layer`/`z`), time, and measurement variables side by side.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check for understanding: dimensionality\n",
    "assert 'layer' in ds.dims\n",
    "assert len(ds.data_vars) > 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting Specific Variables\n",
    "**Show.** We'll peek at layer-based and profile-based variables to see how xsnow differentiates them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run.\n",
    "if ds is None:\n",
    "    raise RuntimeError('Load the dataset above before selecting variables.')\n",
    "\n",
    "if 'density' in ds.data_vars:\n",
    "    density = ds['density']\n",
    "    print('Density dims:', density.dims)\n",
    "    print('Density sample:', float(density.isel(layer=0).mean()))\n",
    "\n",
    "if 'HS' in ds.data_vars:\n",
    "    hs = ds['HS']\n",
    "    print('Snow height dims:', hs.dims)\n",
    "    print('Snow height sample:', float(hs.isel(time=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain.** Layer variables include `layer` or `z`, while profile summaries such as `HS` only vary over time or location.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check for understanding: variable membership\n",
    "assert ('density' in ds.data_vars) or ('HS' in ds.data_vars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Metadata\n",
    "**Show.** We'll read variable and dataset attributes to capture units and processing notes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run.\n",
    "if ds is None:\n",
    "    raise RuntimeError('Load the dataset above before reading metadata.')\n",
    "\n",
    "if 'density' in ds.data_vars:\n",
    "    print(ds['density'].attrs)\n",
    "\n",
    "print('Dataset metadata:', ds.attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain.** Attributes annotate each series with units and descriptions, which keeps scientific context alongside the numbers.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check for understanding: metadata presence\n",
    "assert isinstance(ds.attrs, dict)\n",
    "if 'density' in ds.data_vars:\n",
    "    assert 'units' in ds['density'].attrs or ds['density'].attrs != {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Multiple Files\n",
    "**Show.** Here's how you'd combine several `.pro` or `.smet` files once you have them locally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run.\n",
    "example_paths = ['data/station1.pro', 'data/station2.pro']\n",
    "print('Call xsnow.read(example_paths) when the files are available locally.')\n",
    "print('Or point xsnow.read at a directory to auto-discover compatible files.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain.** `xsnow.read` gracefully merges inputs, aligning coordinates so you can focus on analysis instead of bookkeeping.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Run.\n",
    "# Check for understanding: example path hints\n",
    "assert all(p.startswith('data/') for p in example_paths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Special `z` Coordinate\n",
    "**Show.** Let's grab the vertical coordinate so you can map layers to real-world depths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run.\n",
    "if ds is None:\n",
    "    raise RuntimeError('Load the dataset above before accessing z.')\n",
    "\n",
    "z = ds.coords['z']\n",
    "print('z coordinate head:', z.values[:5])\n",
    "print('Units:', z.attrs.get('units', 'unknown'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain.** Positive-down `z` values map each layer to depth, which keeps stratigraphy analyses consistent.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check for understanding: depth axis\n",
    "assert 'z' in ds.coords\n",
    "assert z.ndim == 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play\n",
    "Experiment by smoothing a temperature profile with different window sizes. Keep it light so execution stays fast.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Run.\n",
    "window = 3  # Try values between 2 and 5\n",
    "if ds is None:\n",
    "    raise RuntimeError('Load the dataset above before playing with smoothing.')\n",
    "\n",
    "if 'temperature' in ds.data_vars:\n",
    "    series = ds['temperature'].isel(location=0, layer=0).to_series()\n",
    "else:\n",
    "    series = ds.to_array().isel(variable=0, location=0, layer=0).to_series()\n",
    "smoothed = series.rolling(window=window, min_periods=1, center=True).mean()\n",
    "print(smoothed.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice\n",
    "Try the prompts before peeking at the solutions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load another xsnow helper dataset and compare its dimensions to the time-series set.\n",
    "2. Plot the mean density over time for one location.\n",
    "3. Inspect metadata for a meteorological variable and explain its units in words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Solutions</summary>\n",
    "\n",
    "1. Use `xsnow.profile_example()` (or another helper) and print `dataset.dims`. Compare the keys to `ds.dims`.\n",
    "2. Select `ds['density']`, average with `.mean(dim='layer')`, and plot with `.to_pandas().plot()`.\n",
    "3. Access something like `ds['TA'].attrs['units']` to describe the temperature units.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- NumPy, pandas, and xarray each support xsnow's layered data structures.\n",
    "- xsnow helper loaders give you quick practice datasets to explore.\n",
    "- Metadata and coordinates keep physical context attached to every array.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}