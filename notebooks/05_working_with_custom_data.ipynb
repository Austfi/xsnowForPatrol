{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05: Working with Custom Data\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Austfi/xsnowForPatrol/blob/main/notebooks/05_working_with_custom_data.ipynb)\n",
    "\n",
    "This notebook shows you how to prepare and load your own SNOWPACK output files into xsnow.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Preparing your own .pro and .smet files\n",
    "- File format requirements\n",
    "- Loading custom data\n",
    "- Troubleshooting common issues\n",
    "- Merging multiple data sources\n",
    "- Data validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation (For Colab Users)\n",
    "\n",
    "If you're using Google Colab, run the cell below to install xsnow and dependencies. If you're running locally and have already installed xsnow, you can skip this cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install xsnow from git (run this cell if using Colab or if you haven't installed yet)\n",
    "# Uncomment the lines below to install:\n",
    "\n",
    "# %pip install -q numpy pandas xarray matplotlib seaborn dask netcdf4\n",
    "# %pip install -q git+https://gitlab.com/avacollabra/postprocessing/xsnow\n",
    "\n",
    "print(\"To install xsnow, uncomment the pip install lines above and run this cell.\")\n",
    "print(\"If xsnow is already installed, you can skip this cell.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xsnow\n",
    "import os\n",
    "import glob\n",
    "\n",
    "print(\"This notebook will help you work with your own data files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Explore xsnow sample data\n",
    "import xsnow\n",
    "\n",
    "print(\"xsnow provides two main sample datasets:\")\n",
    "print()\n",
    "\n",
    "# Example 1: Single profile\n",
    "print(\"1. Single profile (one snapshot):\")\n",
    "try:\n",
    "    ds_single = xsnow.single_profile()\n",
    "    print(f\"   \u2705 Loaded! Dimensions: {dict(ds_single.dims)}\")\n",
    "except Exception as e:\n",
    "    print(f\"   \u274c Error: {e}\")\n",
    "\n",
    "print()\n",
    "# Example 2: Time series\n",
    "print(\"2. Time series (multiple snapshots over time):\")\n",
    "try:\n",
    "    ds_timeseries = xsnow.single_profile_timeseries()\n",
    "    print(f\"   \u2705 Loaded! Dimensions: {dict(ds_timeseries.dims)}\")\n",
    "except Exception as e:\n",
    "    print(f\"   \u274c Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: File Format Requirements\n",
    "\n",
    "xsnow can read SNOWPACK output files in these formats:\n",
    "\n",
    "### .pro Files (Profile Time Series)\n",
    "\n",
    "- **Format**: SNOWPACK profile format (legacy)\n",
    "- **Contains**: Time series of snow profiles with layer-by-layer data\n",
    "- **Required**: Header with station metadata, profile data blocks\n",
    "- **Generated by**: SNOWPACK when `PROF_FORMAT = PRO` in .ini file\n",
    "\n",
    "### .smet Files (Meteorological Time Series)\n",
    "\n",
    "- **Format**: SMET (MeteoIO format)\n",
    "- **Contains**: Time series of scalar variables (no layers)\n",
    "- **Required**: SMET header with field descriptions, time series data\n",
    "- **Generated by**: SNOWPACK or MeteoIO for meteorological data\n",
    "\n",
    "### Other Formats\n",
    "\n",
    "xsnow may support other formats (check documentation):\n",
    "- NetCDF (if SNOWPACK outputs to NetCDF)\n",
    "- Other SNOWPACK output formats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Preparing Your Files\n",
    "\n",
    "### Step 1: Generate SNOWPACK Output\n",
    "\n",
    "If you're running SNOWPACK yourself:\n",
    "\n",
    "1. **Configure SNOWPACK** (via Inishell or .ini file):\n",
    "   - Set `PROF_FORMAT = PRO` to generate .pro files\n",
    "   - Configure which variables to output\n",
    "   - Set output directory\n",
    "\n",
    "2. **Run SNOWPACK** simulation\n",
    "\n",
    "3. **Check output files**:\n",
    "   - Look for `.pro` files in output directory\n",
    "   - Check for `.smet` files if configured\n",
    "\n",
    "### Step 2: Verify File Format\n",
    "\n",
    "Let's check if your files are in the correct format:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for .pro files in data directory\n",
    "data_dir = \"data\"\n",
    "pro_files = glob.glob(os.path.join(data_dir, \"*.pro\"))\n",
    "smet_files = glob.glob(os.path.join(data_dir, \"*.smet\"))\n",
    "\n",
    "print(f\"Found {len(pro_files)} .pro files:\")\n",
    "for f in pro_files[:5]:  # Show first 5\n",
    "    print(f\"  - {os.path.basename(f)}\")\n",
    "\n",
    "print(f\"\\nFound {len(smet_files)} .smet files:\")\n",
    "for f in smet_files[:5]:  # Show first 5\n",
    "    print(f\"  - {os.path.basename(f)}\")\n",
    "\n",
    "# Quick format check\n",
    "if pro_files:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Checking first .pro file format...\")\n",
    "    first_file = pro_files[0]\n",
    "    with open(first_file, 'r') as f:\n",
    "        first_lines = [f.readline() for _ in range(10)]\n",
    "        print(\"First few lines:\")\n",
    "        for i, line in enumerate(first_lines[:5]):\n",
    "            print(f\"  {i+1}: {line.strip()[:80]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Loading Your Custom Data\n",
    "\n",
    "Now let's load your files:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Load a single file\n",
    "if pro_files:\n",
    "    try:\n",
    "        ds = xsnow.read(pro_files[0])\n",
    "        print(f\"\u2705 Successfully loaded: {os.path.basename(pro_files[0])}\")\n",
    "        print(f\"\\nDataset summary:\")\n",
    "        print(f\"  Locations: {ds.dims.get('location', 0)}\")\n",
    "        print(f\"  Time steps: {ds.dims.get('time', 0)}\")\n",
    "        print(f\"  Layers: {ds.dims.get('layer', 0)}\")\n",
    "        print(f\"  Variables: {len(ds.data_vars)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\u274c Error loading file: {e}\")\n",
    "        print(\"\\nTroubleshooting:\")\n",
    "        print(\"1. Check file format is correct\")\n",
    "        print(\"2. Verify file is not corrupted\")\n",
    "        print(\"3. Check xsnow documentation for format requirements\")\n",
    "        ds = None\n",
    "else:\n",
    "    print(\"No .pro files found in data/ directory\")\n",
    "    print(\"\\nTo load your own files:\")\n",
    "    print(\"1. Place .pro or .smet files in the data/ directory\")\n",
    "    print(\"2. Or specify full path: ds = xsnow.read('/path/to/your/file.pro')\")\n",
    "    ds = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Multiple Files\n",
    "\n",
    "You can load multiple files at once:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Load multiple files\n",
    "if len(pro_files) > 1:\n",
    "    try:\n",
    "        ds_multi = xsnow.read(pro_files[:3])  # Load first 3 files\n",
    "        print(f\"\u2705 Successfully loaded {len(pro_files[:3])} files\")\n",
    "        print(f\"  Combined locations: {ds_multi.dims.get('location', 0)}\")\n",
    "        print(f\"  Time steps: {ds_multi.dims.get('time', 0)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\u274c Error loading multiple files: {e}\")\n",
    "        print(\"\\nNote: Files must have compatible formats and time ranges\")\n",
    "else:\n",
    "    print(\"\"\"\n",
    "    Loading multiple files:\n",
    "    \n",
    "    # List of files\n",
    "    ds = xsnow.read(['data/file1.pro', 'data/file2.pro'])\n",
    "    \n",
    "    # All files in directory\n",
    "    ds = xsnow.read('data/')\n",
    "    \n",
    "    # Mix of .pro and .smet\n",
    "    ds = xsnow.read(['data/profile.pro', 'data/meteo.smet'])\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Troubleshooting Common Issues\n",
    "\n",
    "### Issue 1: File Not Found\n",
    "\n",
    "**Error**: `FileNotFoundError` or similar\n",
    "\n",
    "**Solutions**:\n",
    "- Check file path is correct\n",
    "- Use absolute paths if relative paths don't work\n",
    "- Verify file exists: `os.path.exists('path/to/file.pro')`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Check if file exists before loading\n",
    "test_file = \"data/your_file.pro\"\n",
    "if os.path.exists(test_file):\n",
    "    print(f\"\u2705 File exists: {test_file}\")\n",
    "    # ds = xsnow.read(test_file)\n",
    "else:\n",
    "    print(f\"\u274c File not found: {test_file}\")\n",
    "    print(\"\\nTips:\")\n",
    "    print(\"1. Check spelling of filename\")\n",
    "    print(\"2. Use absolute path: /full/path/to/file.pro\")\n",
    "    print(\"3. Check current directory: os.getcwd()\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue 2: Format Not Recognized\n",
    "\n",
    "**Error**: File format not supported or parsing errors\n",
    "\n",
    "**Solutions**:\n",
    "- Verify file is actual .pro or .smet format (not just renamed)\n",
    "- Check file header matches expected format\n",
    "- Try opening file in text editor to inspect structure\n",
    "- Check SNOWPACK version compatibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect file header\n",
    "if pro_files:\n",
    "    print(\"Inspecting file header...\")\n",
    "    with open(pro_files[0], 'r') as f:\n",
    "        header_lines = [f.readline().strip() for _ in range(20)]\n",
    "        print(\"First 20 lines:\")\n",
    "        for i, line in enumerate(header_lines):\n",
    "            if line:  # Skip empty lines\n",
    "                print(f\"  {i+1}: {line[:100]}\")\n",
    "    \n",
    "    print(\"\\nLook for:\")\n",
    "    print(\"  - Station name/identifier\")\n",
    "    print(\"  - Coordinates (latitude, longitude)\")\n",
    "    print(\"  - Column headers\")\n",
    "    print(\"  - Data format indicators\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue 3: Missing Variables\n",
    "\n",
    "**Problem**: Expected variables not in dataset\n",
    "\n",
    "**Solutions**:\n",
    "- Check SNOWPACK output configuration\n",
    "- Verify variables were enabled in SNOWPACK .ini file\n",
    "- Some variables may be computed by xsnow (like HS, z)\n",
    "- Check variable names match xsnow's expected names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Variables in your dataset:\")\n",
    "for var in list(ds.data_vars.keys())[:20]:  # Show first 20\n",
    "    print(f\"  - {var}\")\n",
    "\n",
    "# Check for common variables\n",
    "common_vars = ['density', 'temperature', 'HS', 'grain_type', 'grain_size']\n",
    "print(\"\\nChecking for common variables:\")\n",
    "for var in common_vars:\n",
    "    if var in ds.data_vars:\n",
    "        print(f\"  \u2705 {var}\")\n",
    "else:\n",
    "    print(\"Load data first to check variables\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue 4: Time Alignment Problems\n",
    "\n",
    "**Problem**: Multiple files have different time ranges or frequencies\n",
    "\n",
    "**Solutions**:\n",
    "- xsnow will try to align times automatically\n",
    "- Check time ranges: `ds.coords['time'].values`\n",
    "- Resample if needed: `ds.resample(time='1H').mean()`\n",
    "- Manually select overlapping time periods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = ds.coords['time'].values\n",
    "print(f\"Time range in dataset:\")\n",
    "print(f\"  Start: {times[0]}\")\n",
    "print(f\"  End: {times[-1]}\")\n",
    "print(f\"  Number of time steps: {len(times)}\")\n",
    "\n",
    "# Check time frequency\n",
    "if len(times) > 1:\n",
    "    time_diff = times[1] - times[0]\n",
    "    print(f\"  Time step: {time_diff}\")\n",
    "    \n",
    "print(\"\\nIf merging multiple files with different times:\")\n",
    "print(\"  xsnow will align them automatically\")\n",
    "print(\"  Or manually select: ds.sel(time=slice('2024-01-01', '2024-01-31'))\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Data Validation\n",
    "\n",
    "After loading, validate your data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== DATA VALIDATION ===\")\n",
    "\n",
    "# Check for NaN values\n",
    "if 'density' in ds.data_vars:\n",
    "    nan_count = ds['density'].isnull().sum().values\n",
    "    total_count = ds['density'].size\n",
    "    print(f\"\\nNaN values in density: {nan_count} / {total_count}\")\n",
    "    if nan_count > 0:\n",
    "        print(\"  \u26a0\ufe0f Some NaN values found (may be normal for shallow snowpack)\")\n",
    "\n",
    "# Check for reasonable value ranges\n",
    "if 'density' in ds.data_vars:\n",
    "    density_vals = ds['density'].values\n",
    "    valid_vals = density_vals[~np.isnan(density_vals)]\n",
    "    if len(valid_vals) > 0:\n",
    "        print(f\"\\nDensity range: {valid_vals.min():.1f} to {valid_vals.max():.1f} kg/m\u00b3\")\n",
    "        if valid_vals.min() < 0 or valid_vals.max() > 1000:\n",
    "            print(\"  \u26a0\ufe0f Unusual density values - check data quality\")\n",
    "\n",
    "if 'temperature' in ds.data_vars:\n",
    "    temp_vals = ds['temperature'].values\n",
    "    valid_vals = temp_vals[~np.isnan(temp_vals)]\n",
    "    if len(valid_vals) > 0:\n",
    "        print(f\"Temperature range: {valid_vals.min():.1f} to {valid_vals.max():.1f} \u00b0C\")\n",
    "        if valid_vals.min() < -50 or valid_vals.max() > 10:\n",
    "            print(\"  \u26a0\ufe0f Unusual temperature values - check units\")\n",
    "\n",
    "# Check dimensions\n",
    "print(f\"\\nDataset dimensions:\")\n",
    "for dim, size in ds.dims.items():\n",
    "    print(f\"  {dim}: {size}\")\n",
    "\n",
    "print(\"\\n\u2705 Validation complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Merging Profile and Meteorological Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Merge profile and meteo data\n",
    "if pro_files and smet_files:\n",
    "    try:\n",
    "        # Load both types\n",
    "        ds_combined = xsnow.read([pro_files[0], smet_files[0]])\n",
    "        print(\"\u2705 Successfully merged profile and meteorological data\")\n",
    "        print(f\"  Variables: {len(ds_combined.data_vars)}\")\n",
    "        print(\"\\nVariables from .pro (layer-level):\")\n",
    "        layer_vars = [v for v in ds_combined.data_vars if 'layer' in ds_combined[v].dims]\n",
    "        for v in layer_vars[:5]:\n",
    "            print(f\"  - {v}\")\n",
    "        \n",
    "        print(\"\\nVariables from .smet (profile-level, no layers):\")\n",
    "        profile_vars = [v for v in ds_combined.data_vars if 'layer' not in ds_combined[v].dims]\n",
    "        for v in profile_vars[:5]:\n",
    "            print(f\"  - {v}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error merging: {e}\")\n",
    "else:\n",
    "    print(\"\"\"\n",
    "    Merging profile and meteo data:\n",
    "    \n",
    "    # Load both at once\n",
    "    ds = xsnow.read(['data/profile.pro', 'data/meteo.smet'])\n",
    "    \n",
    "    # Or load separately and merge\n",
    "    ds_pro = xsnow.read('data/profile.pro')\n",
    "    ds_met = xsnow.read('data/meteo.smet')\n",
    "    ds_combined = xsnow.merge([ds_pro, ds_met])  # If merge function exists\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "\u2705 **What we learned:**\n",
    "\n",
    "1. **File formats**: .pro (profiles) and .smet (meteorological) files\n",
    "2. **Loading custom data**: Use `xsnow.read()` with your file paths\n",
    "3. **Multiple files**: Load lists of files or entire directories\n",
    "4. **Troubleshooting**: Common issues and solutions\n",
    "5. **Validation**: Check data quality and ranges\n",
    "6. **Merging**: Combine profile and meteo data\n",
    "\n",
    "## Key Tips\n",
    "\n",
    "- **File paths**: Use absolute paths if relative paths cause issues\n",
    "- **Format verification**: Inspect file headers to ensure correct format\n",
    "- **Variable names**: Check xsnow documentation for expected variable names\n",
    "- **Time alignment**: xsnow handles this automatically when merging\n",
    "- **Data quality**: Always validate loaded data\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Now that you can load your own data:\n",
    "- Apply analysis techniques from previous notebooks\n",
    "- Create visualizations with your data\n",
    "- Or learn to extend xsnow: **06_extending_xsnow.ipynb**\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. Load one of your own .pro files and inspect its structure\n",
    "2. Check for missing variables and verify data ranges\n",
    "3. Load multiple files and compare their time ranges\n",
    "4. Merge a .pro and .smet file if you have both\n",
    "5. Validate your data and identify any quality issues\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}