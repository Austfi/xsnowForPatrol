{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05: Working with Custom Data\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Austfi/xsnowForPatrol/blob/main/notebooks/05_working_with_custom_data.ipynb)\n",
    "\n",
    "This notebook shows you how to prepare and load your own SNOWPACK output files into xsnow.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Preparing your own .pro and .smet files\n",
    "- File format requirements\n",
    "- Loading custom data\n",
    "- Troubleshooting common issues\n",
    "- Merging multiple data sources\n",
    "- Data validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation (For Colab Users)\n",
    "\n",
    "If you're using Google Colab, run the cell below to install xsnow and dependencies. If you're running locally and have already installed xsnow, you can skip this cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%pip install -q numpy pandas xarray matplotlib seaborn dask netcdf4\n",
    "%pip install -q git+https://gitlab.com/avacollabra/postprocessing/xsnow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xsnow\n",
    "import os\n",
    "import glob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Explore xsnow sample data\n",
    "import xsnow\n",
    "\n",
    "print(\"xsnow provides two main sample datasets:\")\n",
    "print()\n",
    "\n",
    "# Example 1: Single profile\n",
    "print(\"1. Single profile (one snapshot):\")\n",
    "try:\n",
    "    ds_single = xsnow.single_profile()\n",
    "    print(f\"   ✅ Loaded! Dimensions: {dict(ds_single.dims)}\")\n",
    "except Exception as e:\n",
    "    print(f\"   ❌ Error: {e}\")\n",
    "\n",
    "print()\n",
    "# Example 2: Time series\n",
    "print(\"2. Time series (multiple snapshots over time):\")\n",
    "try:\n",
    "    ds_timeseries = xsnow.single_profile_timeseries()\n",
    "    print(f\"   ✅ Loaded! Dimensions: {dict(ds_timeseries.dims)}\")\n",
    "except Exception as e:\n",
    "    print(f\"   ❌ Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: File Format Requirements\n",
    "\n",
    "xsnow can read SNOWPACK output files in these formats:\n",
    "\n",
    "### .pro Files (Profile Time Series)\n",
    "\n",
    "- **Format**: SNOWPACK profile format (legacy)\n",
    "- **Contains**: Time series of snow profiles with layer-by-layer data\n",
    "- **Required**: Header with station metadata, profile data blocks\n",
    "- **Generated by**: SNOWPACK when `PROF_FORMAT = PRO` in .ini file\n",
    "\n",
    "### .smet Files (Meteorological Time Series)\n",
    "\n",
    "- **Format**: SMET (MeteoIO format)\n",
    "- **Contains**: Time series of scalar variables (no layers)\n",
    "- **Required**: SMET header with field descriptions, time series data\n",
    "- **Generated by**: SNOWPACK or MeteoIO for meteorological data\n",
    "\n",
    "### Other Formats\n",
    "\n",
    "xsnow may support other formats (check documentation):\n",
    "- NetCDF (if SNOWPACK outputs to NetCDF)\n",
    "- Other SNOWPACK output formats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Preparing Your Files\n",
    "\n",
    "### Step 1: Generate SNOWPACK Output\n",
    "\n",
    "If you're running SNOWPACK yourself:\n",
    "\n",
    "1. **Configure SNOWPACK** (via Inishell or .ini file):\n",
    "   - Set `PROF_FORMAT = PRO` to generate .pro files\n",
    "   - Configure which variables to output\n",
    "   - Set output directory\n",
    "\n",
    "2. **Run SNOWPACK** simulation\n",
    "\n",
    "3. **Check output files**:\n",
    "   - Look for `.pro` files in output directory\n",
    "   - Check for `.smet` files if configured\n",
    "\n",
    "### Step 2: Verify File Format\n",
    "\n",
    "Let's check if your files are in the correct format:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for .pro files in data directory\n",
    "data_dir = \"data\"\n",
    "pro_files = glob.glob(os.path.join(data_dir, \"*.pro\"))\n",
    "smet_files = glob.glob(os.path.join(data_dir, \"*.smet\"))\n",
    "\n",
    "print(f\"Found {len(pro_files)} .pro files:\")\n",
    "for f in pro_files[:5]:  # Show first 5\n",
    "    print(f\"  {f}\")\n",
    "\n",
    "print(f\"\\nFound {len(smet_files)} .smet files:\")\n",
    "for f in smet_files[:5]:  # Show first 5\n",
    "    print(f\"  {f}\")\n",
    "\n",
    "# Quick format check\n",
    "if pro_files:\n",
    "    first_file = pro_files[0]\n",
    "    print(f\"\\nInspecting first .pro file: {first_file}\")\n",
    "    with open(first_file, 'r') as f:\n",
    "        first_lines = [f.readline() for _ in range(10)]\n",
    "        print(\"First 5 non-empty lines:\")\n",
    "        for i, line in enumerate(first_lines[:5]):\n",
    "            if line.strip():  # Only show non-empty lines\n",
    "                print(f\"  Line {i+1}: {line.strip()[:80]}\")\n",
    "else:\n",
    "    print(\"\\nNo .pro files found in data directory.\")\n",
    "    print(\"Note: You can use xsnow's built-in sample data instead!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Loading Your Custom Data\n",
    "\n",
    "Now let's load your files:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Load a single file\n",
    "if pro_files:\n",
    "    try:\n",
    "        ds = xsnow.read(pro_files[0])\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading file: {e}\")\n",
    "        ds = None\n",
    "else:\n",
    "    ds = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Multiple Files\n",
    "\n",
    "You can load multiple files at once:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Load multiple files\n",
    "if len(pro_files) > 1:\n",
    "    try:\n",
    "        ds_multi = xsnow.read(pro_files[:3])  # Load first 3 files\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading multiple files: {e}\")\n",
    "else:\n",
    "    Loading multiple files:\n",
    "    \n",
    "    # List of files\n",
    "    ds = xsnow.read(['data/file1.pro', 'data/file2.pro'])\n",
    "    \n",
    "    # All files in directory\n",
    "    ds = xsnow.read('data/')\n",
    "    \n",
    "    # Mix of .pro and .smet\n",
    "    ds = xsnow.read(['data/profile.pro', 'data/meteo.smet'])\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Troubleshooting Common Issues\n",
    "\n",
    "### Issue 1: File Not Found\n",
    "\n",
    "**Error**: `FileNotFoundError` or similar\n",
    "\n",
    "**Solutions**:\n",
    "- Check file path is correct\n",
    "- Use absolute paths if relative paths don't work\n",
    "- Verify file exists: `os.path.exists('path/to/file.pro')`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Check if file exists before loading\n",
    "test_file = \"data/your_file.pro\"\n",
    "if os.path.exists(test_file):\n",
    "    # ds = xsnow.read(test_file)\n",
    "else:\n",
    "    print(f\"❌ File not found: {test_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue 2: Format Not Recognized\n",
    "\n",
    "**Error**: File format not supported or parsing errors\n",
    "\n",
    "**Solutions**:\n",
    "- Verify file is actual .pro or .smet format (not just renamed)\n",
    "- Check file header matches expected format\n",
    "- Try opening file in text editor to inspect structure\n",
    "- Check SNOWPACK version compatibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect file header\n",
    "if pro_files:\n",
    "    print(f\"Inspecting header of: {pro_files[0]}\")\n",
    "    with open(pro_files[0], 'r') as f:\n",
    "        header_lines = [f.readline().strip() for _ in range(20)]\n",
    "        print(\"Header lines (first 20, non-empty):\")\n",
    "        for i, line in enumerate(header_lines):\n",
    "            if line:  # Skip empty lines\n",
    "                print(f\"  {i+1}: {line[:100]}\")\n",
    "else:\n",
    "    print(\"No .pro files available to inspect.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue 3: Missing Variables\n",
    "\n",
    "**Problem**: Expected variables not in dataset\n",
    "\n",
    "**Solutions**:\n",
    "- Check SNOWPACK output configuration\n",
    "- Verify variables were enabled in SNOWPACK .ini file\n",
    "- Some variables may be computed by xsnow (like HS, z)\n",
    "- Check variable names match xsnow's expected names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ds is not None:\n",
    "    print(\"Available variables in dataset (first 20):\")\n",
    "    for var in list(ds.data_vars.keys())[:20]:\n",
    "        print(f\"  {var}: {ds[var].dims}\")\n",
    "\n",
    "    # Check for common variables\n",
    "    print(\"\\nChecking for common variables:\")\n",
    "    common_vars = ['density', 'temperature', 'HS', 'grain_type', 'grain_size']\n",
    "    for var in common_vars:\n",
    "        if var in ds.data_vars:\n",
    "            print(f\"  ✅ {var}: found\")\n",
    "        else:\n",
    "            print(f\"  ❌ {var}: not found\")\n",
    "else:\n",
    "    print(\"No dataset loaded. Load a dataset first using xsnow.read()\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue 4: Time Alignment Problems\n",
    "\n",
    "**Problem**: Multiple files have different time ranges or frequencies\n",
    "\n",
    "**Solutions**:\n",
    "- xsnow will try to align times automatically\n",
    "- Check time ranges: `ds.coords['time'].values`\n",
    "- Resample if needed: `ds.resample(time='1H').mean()`\n",
    "- Manually select overlapping time periods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ds is not None and 'time' in ds.coords:\n",
    "    times = ds.coords['time'].values\n",
    "    \n",
    "    print(f\"Time range: {times[0]} to {times[-1]}\")\n",
    "    print(f\"Total time steps: {len(times)}\")\n",
    "    \n",
    "    # Check time frequency\n",
    "    if len(times) > 1:\n",
    "        time_diff = times[1] - times[0]\n",
    "        print(f\"Time step frequency: {time_diff}\")\n",
    "        \n",
    "        # Check if times are regular\n",
    "        if len(times) > 2:\n",
    "            time_diffs = np.diff(times)\n",
    "            if np.allclose(time_diffs, time_diffs[0]):\n",
    "                print(\"✅ Times are regularly spaced\")\n",
    "            else:\n",
    "                print(\"⚠️ Times are irregularly spaced\")\n",
    "else:\n",
    "    print(\"No time coordinate available in dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Data Validation\n",
    "\n",
    "After loading, validate your data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check for NaN values\n",
    "if ds is not None and 'density' in ds.data_vars:\n",
    "    nan_count = ds['density'].isnull().sum().values\n",
    "    total_count = ds['density'].size\n",
    "    if nan_count > 0:\n",
    "        print(f\"⚠️ Found {nan_count} NaN values in density ({100*nan_count/total_count:.1f}%)\")\n",
    "    else:\n",
    "        print(\"✅ No NaN values in density\")\n",
    "\n",
    "# Check for reasonable value ranges\n",
    "if ds is not None and 'density' in ds.data_vars:\n",
    "    density_vals = ds['density'].values\n",
    "    valid_vals = density_vals[~np.isnan(density_vals)]\n",
    "    if len(valid_vals) > 0:\n",
    "        print(f\"Density range: {valid_vals.min():.1f} to {valid_vals.max():.1f} kg/m³\")\n",
    "        if valid_vals.min() < 0 or valid_vals.max() > 1000:\n",
    "            print(\"⚠️ Density values outside typical range (0-1000 kg/m³)\")\n",
    "        else:\n",
    "            print(\"✅ Density values in reasonable range\")\n",
    "\n",
    "if ds is not None and 'temperature' in ds.data_vars:\n",
    "    temp_vals = ds['temperature'].values\n",
    "    valid_vals = temp_vals[~np.isnan(temp_vals)]\n",
    "    if len(valid_vals) > 0:\n",
    "        print(f\"Temperature range: {valid_vals.min():.1f} to {valid_vals.max():.1f} °C\")\n",
    "        if valid_vals.min() < -50 or valid_vals.max() > 10:\n",
    "            print(\"⚠️ Temperature values outside typical range (-50 to 10 °C)\")\n",
    "        else:\n",
    "            print(\"✅ Temperature values in reasonable range\")\n",
    "\n",
    "# Check dimensions\n",
    "if ds is not None:\n",
    "    print(\"\\nDataset dimensions:\")\n",
    "    for dim, size in ds.dims.items():\n",
    "        print(f\"  {dim}: {size}\")\n",
    "else:\n",
    "    print(\"No dataset loaded for validation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Merging Profile and Meteorological Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Merge profile and meteo data\n",
    "if pro_files and smet_files:\n",
    "    try:\n",
    "        # Load both types\n",
    "        ds_combined = xsnow.read([pro_files[0], smet_files[0]])\n",
    "        print(\"✅ Successfully merged profile and meteo data\")\n",
    "        \n",
    "        layer_vars = [v for v in ds_combined.data_vars if 'layer' in ds_combined[v].dims]\n",
    "        print(f\"\\nLayer-level variables (first 5):\")\n",
    "        for v in layer_vars[:5]:\n",
    "            print(f\"  {v}: {ds_combined[v].dims}\")\n",
    "        \n",
    "        profile_vars = [v for v in ds_combined.data_vars if 'layer' not in ds_combined[v].dims]\n",
    "        print(f\"\\nProfile-level variables (first 5):\")\n",
    "        for v in profile_vars[:5]:\n",
    "            print(f\"  {v}: {ds_combined[v].dims}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error merging: {e}\")\n",
    "else:\n",
    "    print(\"\"\"\n",
    "    Merging profile and meteo data:\n",
    "    \n",
    "    # Load both at once\n",
    "    ds = xsnow.read(['data/profile.pro', 'data/meteo.smet'])\n",
    "    \n",
    "    # Or load separately and merge\n",
    "    ds_pro = xsnow.read('data/profile.pro')\n",
    "    ds_met = xsnow.read('data/meteo.smet')\n",
    "    ds_combined = xr.merge([ds_pro, ds_met])  # Using xarray's merge\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "✅ **What we learned:**\n",
    "\n",
    "1. **File formats**: .pro (profiles) and .smet (meteorological) files\n",
    "2. **Loading custom data**: Use `xsnow.read()` with your file paths\n",
    "3. **Multiple files**: Load lists of files or entire directories\n",
    "4. **Troubleshooting**: Common issues and solutions\n",
    "5. **Validation**: Check data quality and ranges\n",
    "6. **Merging**: Combine profile and meteo data\n",
    "\n",
    "## Key Tips\n",
    "\n",
    "- **File paths**: Use absolute paths if relative paths cause issues\n",
    "- **Format verification**: Inspect file headers to ensure correct format\n",
    "- **Variable names**: Check xsnow documentation for expected variable names\n",
    "- **Time alignment**: xsnow handles this automatically when merging\n",
    "- **Data quality**: Always validate loaded data\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Now that you can load your own data:\n",
    "- Apply analysis techniques from previous notebooks\n",
    "- Create visualizations with your data\n",
    "- Or learn to extend xsnow: **06_extending_xsnow.ipynb**\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. Load one of your own .pro files and inspect its structure\n",
    "2. Check for missing variables and verify data ranges\n",
    "3. Load multiple files and compare their time ranges\n",
    "4. Merge a .pro and .smet file if you have both\n",
    "5. Validate your data and identify any quality issues\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
