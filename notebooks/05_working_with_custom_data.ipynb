{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version compatibility check\n",
    "\n",
    "This notebook compares the xsnow package installed in your environment with the documentation version it was written for.",
    " The helper below calls `scripts/check_docs_version.py` so you can confirm that the package and docs align before continuing.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "\n",
    "def _find_script() -> Path | None:\n",
    "    current = Path.cwd().resolve()\n",
    "    for candidate in [current, *current.parents]:\n",
    "        script = candidate / \"scripts\" / \"check_docs_version.py\"\n",
    "        if script.exists():\n",
    "            return script\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_docs_version() -> tuple[str | None, str | None]:\n",
    "    script_path = _find_script()\n",
    "    if script_path is None:\n",
    "        return None, \"scripts/check_docs_version.py was not found\"\n",
    "    try:\n",
    "        completed = subprocess.run(\n",
    "            [sys.executable, str(script_path)],\n",
    "            check=True,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "        )\n",
    "    except subprocess.CalledProcessError as exc:\n",
    "        output = (exc.stdout or \"\") + (exc.stderr or \"\")\n",
    "        return None, output.strip() or str(exc)\n",
    "    return completed.stdout.strip() or None, None\n",
    "\n",
    "\n",
    "docs_version, docs_error = get_docs_version()\n",
    "\n",
    "try:\n",
    "    import xsnow\n",
    "    package_version = xsnow.__version__\n",
    "except Exception as exc:  # pylint: disable=broad-except\n",
    "    xsnow = None  # type: ignore[assignment]\n",
    "    package_version = None\n",
    "    package_error = str(exc)\n",
    "else:\n",
    "    package_error = None\n",
    "\n",
    "print(f\"xsnow package version: {package_version if package_version else 'not installed'}\")\n",
    "if package_error and not package_version:\n",
    "    print(f\"Import error: {package_error}\")\n",
    "\n",
    "if docs_version:\n",
    "    print(f\"xsnow docs version: {docs_version}\")\n",
    "else:\n",
    "    message = \"xsnow docs version: unavailable\"\n",
    "    if docs_error:\n",
    "        message += f\" ({docs_error})\"\n",
    "    print(message)\n",
    "\n",
    "if docs_version and package_version and docs_version != package_version:\n",
    "    warnings.warn(\n",
    "        \"xsnow package version differs from the documentation version. \"\n",
    "        \"Consider aligning them before executing the notebook.\",\n",
    "        stacklevel=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05: Working with Custom Data\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Austfi/xsnowForPatrol/blob/main/notebooks/05_working_with_custom_data.ipynb)\n",
    "\n",
    "This notebook shows you how to prepare and load your own SNOWPACK output files into xsnow.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Preparing your own .pro and .smet files\n",
    "- File format requirements\n",
    "- Loading custom data\n",
    "- Troubleshooting common issues\n",
    "- Merging multiple data sources\n",
    "- Data validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation (For Colab Users)\n",
    "\n",
    "Set `INSTALL_XSNOW = True` in the next cell if you need to install xsnow. ",
    "When enabled you can pick `INSTALL_METHOD = \"pip\"` to install published packages or `INSTALL_METHOD = \"dev\"` to work from a local clone.",
    " The cell also installs the supporting scientific Python stack used throughout the course.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "INSTALL_XSNOW = False  # Set to True to install or update xsnow in this environment.\n",
    "INSTALL_METHOD = \"pip\"  # Choose \"pip\" for a package install, or \"dev\" for a developer clone.\n",
    "DEV_REPO_URL = \"https://gitlab.com/avacollabra/postprocessing/xsnow.git\"\n",
    "DEV_CLONE_DIR = Path.home() / \"xsnow-dev\"\n",
    "\n",
    "\n",
    "def _run(cmd: list[str]) -> None:\n",
    "    print(f\"$ {' '.join(cmd)}\")\n",
    "    subprocess.check_call(cmd)\n",
    "\n",
    "\n",
    "try:\n",
    "    import xsnow\n",
    "    print(f\"xsnow {xsnow.__version__} is already available.\")\n",
    "except Exception as exc:  # pylint: disable=broad-except\n",
    "    xsnow = None  # type: ignore[assignment]\n",
    "    print(f\"xsnow is not currently available: {exc}\")\n",
    "    if not INSTALL_XSNOW:\n",
    "        print(\"Set INSTALL_XSNOW = True and re-run this cell to install xsnow (pip or dev clone).\")\n",
    "    else:\n",
    "        try:\n",
    "            if INSTALL_METHOD == \"pip\":\n",
    "                _run([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", \"numpy\", \"pandas\", \"xarray\", \"matplotlib\", \"seaborn\", \"dask\", \"netcdf4\"])\n",
    "                _run([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", \"git+https://gitlab.com/avacollabra/postprocessing/xsnow\"])\n",
    "            elif INSTALL_METHOD == \"dev\":\n",
    "                if not DEV_CLONE_DIR.exists():\n",
    "                    _run([\"git\", \"clone\", DEV_REPO_URL, str(DEV_CLONE_DIR)])\n",
    "                _run([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", \"-e\", str(DEV_CLONE_DIR)])\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported INSTALL_METHOD: {INSTALL_METHOD}\")\n",
    "        except subprocess.CalledProcessError as install_error:\n",
    "            raise RuntimeError(\"xsnow installation command failed\") from install_error\n",
    "        import xsnow  # noqa: F401  # pylint: disable=import-outside-toplevel\n",
    "        print(f\"xsnow {xsnow.__version__} installed successfully.\")\n",
    "else:\n",
    "    INSTALL_XSNOW = INSTALL_XSNOW  # no-op so variable is defined for later cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xsnow\n",
    "import os\n",
    "import glob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Explore xsnow sample data\n",
    "import xsnow\n",
    "\n",
    "print(\"xsnow provides two main sample datasets:\")\n",
    "print()\n",
    "\n",
    "# Example 1: Single profile\n",
    "print(\"1. Single profile (one snapshot):\")\n",
    "try:\n",
    "    ds_single = xsnow.single_profile()\n",
    "    print(f\"   \u2705 Loaded! Dimensions: {dict(ds_single.dims)}\")\n",
    "except Exception as e:\n",
    "    print(f\"   \u274c Error: {e}\")\n",
    "\n",
    "print()\n",
    "# Example 2: Time series\n",
    "print(\"2. Time series (multiple snapshots over time):\")\n",
    "try:\n",
    "    ds_timeseries = xsnow.single_profile_timeseries()\n",
    "    print(f\"   \u2705 Loaded! Dimensions: {dict(ds_timeseries.dims)}\")\n",
    "except Exception as e:\n",
    "    print(f\"   \u274c Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: File Format Requirements\n",
    "\n",
    "xsnow can read SNOWPACK output files in these formats:\n",
    "\n",
    "### .pro Files (Profile Time Series)\n",
    "\n",
    "- **Format**: SNOWPACK profile format (legacy)\n",
    "- **Contains**: Time series of snow profiles with layer-by-layer data\n",
    "- **Required**: Header with station metadata, profile data blocks\n",
    "- **Generated by**: SNOWPACK when `PROF_FORMAT = PRO` in .ini file\n",
    "\n",
    "### .smet Files (Meteorological Time Series)\n",
    "\n",
    "- **Format**: SMET (MeteoIO format)\n",
    "- **Contains**: Time series of scalar variables (no layers)\n",
    "- **Required**: SMET header with field descriptions, time series data\n",
    "- **Generated by**: SNOWPACK or MeteoIO for meteorological data\n",
    "\n",
    "### Other Formats\n",
    "\n",
    "xsnow may support other formats (check documentation):\n",
    "- NetCDF (if SNOWPACK outputs to NetCDF)\n",
    "- Other SNOWPACK output formats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Preparing Your Files\n",
    "\n",
    "### Step 1: Generate SNOWPACK Output\n",
    "\n",
    "If you're running SNOWPACK yourself:\n",
    "\n",
    "1. **Configure SNOWPACK** (via Inishell or .ini file):\n",
    "   - Set `PROF_FORMAT = PRO` to generate .pro files\n",
    "   - Configure which variables to output\n",
    "   - Set output directory\n",
    "\n",
    "2. **Run SNOWPACK** simulation\n",
    "\n",
    "3. **Check output files**:\n",
    "   - Look for `.pro` files in output directory\n",
    "   - Check for `.smet` files if configured\n",
    "\n",
    "### Step 2: Verify File Format\n",
    "\n",
    "Let's check if your files are in the correct format:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for .pro files in data directory\n",
    "data_dir = \"data\"\n",
    "pro_files = glob.glob(os.path.join(data_dir, \"*.pro\"))\n",
    "smet_files = glob.glob(os.path.join(data_dir, \"*.smet\"))\n",
    "\n",
    "for f in pro_files[:5]:  # Show first 5\n",
    "\n",
    "for f in smet_files[:5]:  # Show first 5\n",
    "\n",
    "# Quick format check\n",
    "if pro_files:\n",
    "    first_file = pro_files[0]\n",
    "    with open(first_file, 'r') as f:\n",
    "        first_lines = [f.readline() for _ in range(10)]\n",
    "        for i, line in enumerate(first_lines[:5]):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Loading Your Custom Data\n",
    "\n",
    "Now let's load your files:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Load a single file\n",
    "if pro_files:\n",
    "    try:\n",
    "        ds = xsnow.read(pro_files[0])\n",
    "    except Exception as e:\n",
    "        print(f\"\u274c Error loading file: {e}\")\n",
    "        ds = None\n",
    "else:\n",
    "    ds = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Multiple Files\n",
    "\n",
    "You can load multiple files at once:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Load multiple files\n",
    "if len(pro_files) > 1:\n",
    "    try:\n",
    "        ds_multi = xsnow.read(pro_files[:3])  # Load first 3 files\n",
    "    except Exception as e:\n",
    "        print(f\"\u274c Error loading multiple files: {e}\")\n",
    "else:\n",
    "    Loading multiple files:\n",
    "    \n",
    "    # List of files\n",
    "    ds = xsnow.read(['data/file1.pro', 'data/file2.pro'])\n",
    "    \n",
    "    # All files in directory\n",
    "    ds = xsnow.read('data/')\n",
    "    \n",
    "    # Mix of .pro and .smet\n",
    "    ds = xsnow.read(['data/profile.pro', 'data/meteo.smet'])\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Troubleshooting Common Issues\n",
    "\n",
    "### Issue 1: File Not Found\n",
    "\n",
    "**Error**: `FileNotFoundError` or similar\n",
    "\n",
    "**Solutions**:\n",
    "- Check file path is correct\n",
    "- Use absolute paths if relative paths don't work\n",
    "- Verify file exists: `os.path.exists('path/to/file.pro')`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Check if file exists before loading\n",
    "test_file = \"data/your_file.pro\"\n",
    "if os.path.exists(test_file):\n",
    "    # ds = xsnow.read(test_file)\n",
    "else:\n",
    "    print(f\"\u274c File not found: {test_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue 2: Format Not Recognized\n",
    "\n",
    "**Error**: File format not supported or parsing errors\n",
    "\n",
    "**Solutions**:\n",
    "- Verify file is actual .pro or .smet format (not just renamed)\n",
    "- Check file header matches expected format\n",
    "- Try opening file in text editor to inspect structure\n",
    "- Check SNOWPACK version compatibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect file header\n",
    "if pro_files:\n",
    "    with open(pro_files[0], 'r') as f:\n",
    "        header_lines = [f.readline().strip() for _ in range(20)]\n",
    "        for i, line in enumerate(header_lines):\n",
    "            if line:  # Skip empty lines\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue 3: Missing Variables\n",
    "\n",
    "**Problem**: Expected variables not in dataset\n",
    "\n",
    "**Solutions**:\n",
    "- Check SNOWPACK output configuration\n",
    "- Verify variables were enabled in SNOWPACK .ini file\n",
    "- Some variables may be computed by xsnow (like HS, z)\n",
    "- Check variable names match xsnow's expected names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in list(ds.data_vars.keys())[:20]:  # Show first 20\n",
    "\n",
    "# Check for common variables\n",
    "common_vars = ['density', 'temperature', 'HS', 'grain_type', 'grain_size']\n",
    "for var in common_vars:\n",
    "    if var in ds.data_vars:\n",
    "else:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue 4: Time Alignment Problems\n",
    "\n",
    "**Problem**: Multiple files have different time ranges or frequencies\n",
    "\n",
    "**Solutions**:\n",
    "- xsnow will try to align times automatically\n",
    "- Check time ranges: `ds.coords['time'].values`\n",
    "- Resample if needed: `ds.resample(time='1H').mean()`\n",
    "- Manually select overlapping time periods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = ds.coords['time'].values\n",
    "\n",
    "# Check time frequency\n",
    "if len(times) > 1:\n",
    "    time_diff = times[1] - times[0]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Data Validation\n",
    "\n",
    "After loading, validate your data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check for NaN values\n",
    "if 'density' in ds.data_vars:\n",
    "    nan_count = ds['density'].isnull().sum().values\n",
    "    total_count = ds['density'].size\n",
    "    if nan_count > 0:\n",
    "\n",
    "# Check for reasonable value ranges\n",
    "if 'density' in ds.data_vars:\n",
    "    density_vals = ds['density'].values\n",
    "    valid_vals = density_vals[~np.isnan(density_vals)]\n",
    "    if len(valid_vals) > 0:\n",
    "        if valid_vals.min() < 0 or valid_vals.max() > 1000:\n",
    "\n",
    "if 'temperature' in ds.data_vars:\n",
    "    temp_vals = ds['temperature'].values\n",
    "    valid_vals = temp_vals[~np.isnan(temp_vals)]\n",
    "    if len(valid_vals) > 0:\n",
    "        if valid_vals.min() < -50 or valid_vals.max() > 10:\n",
    "\n",
    "# Check dimensions\n",
    "for dim, size in ds.dims.items():\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Merging Profile and Meteorological Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Merge profile and meteo data\n",
    "if pro_files and smet_files:\n",
    "    try:\n",
    "        # Load both types\n",
    "        ds_combined = xsnow.read([pro_files[0], smet_files[0]])\n",
    "        layer_vars = [v for v in ds_combined.data_vars if 'layer' in ds_combined[v].dims]\n",
    "        for v in layer_vars[:5]:\n",
    "        \n",
    "        profile_vars = [v for v in ds_combined.data_vars if 'layer' not in ds_combined[v].dims]\n",
    "        for v in profile_vars[:5]:\n",
    "    except Exception as e:\n",
    "        print(f\"Error merging: {e}\")\n",
    "else:\n",
    "    Merging profile and meteo data:\n",
    "    \n",
    "    # Load both at once\n",
    "    ds = xsnow.read(['data/profile.pro', 'data/meteo.smet'])\n",
    "    \n",
    "    # Or load separately and merge\n",
    "    ds_pro = xsnow.read('data/profile.pro')\n",
    "    ds_met = xsnow.read('data/meteo.smet')\n",
    "    ds_combined = xsnow.merge([ds_pro, ds_met])  # If merge function exists\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "\u2705 **What we learned:**\n",
    "\n",
    "1. **File formats**: .pro (profiles) and .smet (meteorological) files\n",
    "2. **Loading custom data**: Use `xsnow.read()` with your file paths\n",
    "3. **Multiple files**: Load lists of files or entire directories\n",
    "4. **Troubleshooting**: Common issues and solutions\n",
    "5. **Validation**: Check data quality and ranges\n",
    "6. **Merging**: Combine profile and meteo data\n",
    "\n",
    "## Key Tips\n",
    "\n",
    "- **File paths**: Use absolute paths if relative paths cause issues\n",
    "- **Format verification**: Inspect file headers to ensure correct format\n",
    "- **Variable names**: Check xsnow documentation for expected variable names\n",
    "- **Time alignment**: xsnow handles this automatically when merging\n",
    "- **Data quality**: Always validate loaded data\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Now that you can load your own data:\n",
    "- Apply analysis techniques from previous notebooks\n",
    "- Create visualizations with your data\n",
    "- Or learn to extend xsnow: **06_extending_xsnow.ipynb**\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. Load one of your own .pro files and inspect its structure\n",
    "2. Check for missing variables and verify data ranges\n",
    "3. Load multiple files and compare their time ranges\n",
    "4. Merge a .pro and .smet file if you have both\n",
    "5. Validate your data and identify any quality issues\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}