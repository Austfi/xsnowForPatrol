{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version compatibility check\n",
    "\n",
    "This notebook compares the xsnow package installed in your environment with the documentation version it was written for.",
    " The helper below calls `scripts/check_docs_version.py` so you can confirm that the package and docs align before continuing.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "\n",
    "def _find_script() -> Path | None:\n",
    "    current = Path.cwd().resolve()\n",
    "    for candidate in [current, *current.parents]:\n",
    "        script = candidate / \"scripts\" / \"check_docs_version.py\"\n",
    "        if script.exists():\n",
    "            return script\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_docs_version() -> tuple[str | None, str | None]:\n",
    "    script_path = _find_script()\n",
    "    if script_path is None:\n",
    "        return None, \"scripts/check_docs_version.py was not found\"\n",
    "    try:\n",
    "        completed = subprocess.run(\n",
    "            [sys.executable, str(script_path)],\n",
    "            check=True,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "        )\n",
    "    except subprocess.CalledProcessError as exc:\n",
    "        output = (exc.stdout or \"\") + (exc.stderr or \"\")\n",
    "        return None, output.strip() or str(exc)\n",
    "    return completed.stdout.strip() or None, None\n",
    "\n",
    "\n",
    "docs_version, docs_error = get_docs_version()\n",
    "\n",
    "try:\n",
    "    import xsnow\n",
    "    package_version = xsnow.__version__\n",
    "except Exception as exc:  # pylint: disable=broad-except\n",
    "    xsnow = None  # type: ignore[assignment]\n",
    "    package_version = None\n",
    "    package_error = str(exc)\n",
    "else:\n",
    "    package_error = None\n",
    "\n",
    "print(f\"xsnow package version: {package_version if package_version else 'not installed'}\")\n",
    "if package_error and not package_version:\n",
    "    print(f\"Import error: {package_error}\")\n",
    "\n",
    "if docs_version:\n",
    "    print(f\"xsnow docs version: {docs_version}\")\n",
    "else:\n",
    "    message = \"xsnow docs version: unavailable\"\n",
    "    if docs_error:\n",
    "        message += f\" ({docs_error})\"\n",
    "    print(message)\n",
    "\n",
    "if docs_version and package_version and docs_version != package_version:\n",
    "    warnings.warn(\n",
    "        \"xsnow package version differs from the documentation version. \"\n",
    "        \"Consider aligning them before executing the notebook.\",\n",
    "        stacklevel=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04: Advanced Analysis\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Austfi/xsnowForPatrol/blob/main/notebooks/04_advanced_analysis.ipynb)\n",
    "\n",
    "This notebook covers advanced snowpack analysis techniques including stability indices, hazard calculations, and using xsnow extensions.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Stability indices and their calculation\n",
    "- Hazard chart calculations\n",
    "- Critical crack length\n",
    "- Comparing multiple locations and scenarios\n",
    "- Advanced temporal analysis\n",
    "- Using xsnow extensions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation (For Colab Users)\n",
    "\n",
    "Set `INSTALL_XSNOW = True` in the next cell if you need to install xsnow. ",
    "When enabled you can pick `INSTALL_METHOD = \"pip\"` to install published packages or `INSTALL_METHOD = \"dev\"` to work from a local clone.",
    " The cell also installs the supporting scientific Python stack used throughout the course.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "INSTALL_XSNOW = False  # Set to True to install or update xsnow in this environment.\n",
    "INSTALL_METHOD = \"pip\"  # Choose \"pip\" for a package install, or \"dev\" for a developer clone.\n",
    "DEV_REPO_URL = \"https://gitlab.com/avacollabra/postprocessing/xsnow.git\"\n",
    "DEV_CLONE_DIR = Path.home() / \"xsnow-dev\"\n",
    "\n",
    "\n",
    "def _run(cmd: list[str]) -> None:\n",
    "    print(f\"$ {' '.join(cmd)}\")\n",
    "    subprocess.check_call(cmd)\n",
    "\n",
    "\n",
    "try:\n",
    "    import xsnow\n",
    "    print(f\"xsnow {xsnow.__version__} is already available.\")\n",
    "except Exception as exc:  # pylint: disable=broad-except\n",
    "    xsnow = None  # type: ignore[assignment]\n",
    "    print(f\"xsnow is not currently available: {exc}\")\n",
    "    if not INSTALL_XSNOW:\n",
    "        print(\"Set INSTALL_XSNOW = True and re-run this cell to install xsnow (pip or dev clone).\")\n",
    "    else:\n",
    "        try:\n",
    "            if INSTALL_METHOD == \"pip\":\n",
    "                _run([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", \"numpy\", \"pandas\", \"xarray\", \"matplotlib\", \"seaborn\", \"dask\", \"netcdf4\"])\n",
    "                _run([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", \"git+https://gitlab.com/avacollabra/postprocessing/xsnow\"])\n",
    "            elif INSTALL_METHOD == \"dev\":\n",
    "                if not DEV_CLONE_DIR.exists():\n",
    "                    _run([\"git\", \"clone\", DEV_REPO_URL, str(DEV_CLONE_DIR)])\n",
    "                _run([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", \"-e\", str(DEV_CLONE_DIR)])\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported INSTALL_METHOD: {INSTALL_METHOD}\")\n",
    "        except subprocess.CalledProcessError as install_error:\n",
    "            raise RuntimeError(\"xsnow installation command failed\") from install_error\n",
    "        import xsnow  # noqa: F401  # pylint: disable=import-outside-toplevel\n",
    "        print(f\"xsnow {xsnow.__version__} installed successfully.\")\n",
    "else:\n",
    "    INSTALL_XSNOW = INSTALL_XSNOW  # no-op so variable is defined for later cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xsnow\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load xsnow's lightweight sample time series dataset\n",
    "print(\"Loading xsnow sample data for advanced analysis...\")\n",
    "print(\"Using xsnow.single_profile_timeseries()\")\n",
    "\n",
    "try:\n",
    "    ds = xsnow.single_profile_timeseries()\n",
    "    print(\"\u2705 Data loaded for advanced analysis\")\n",
    "    print(f\"Dataset dimensions: {dict(ds.dims)}\")\n",
    "except Exception as e:\n",
    "    print(f\"\u26a0\ufe0f Error loading sample data: {e}\")\n",
    "    print(\"Make sure xsnow is properly installed:\")\n",
    "    print(\"  pip install git+https://gitlab.com/avacollabra/postprocessing/xsnow\")\n",
    "    ds = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Stability Indices\n",
    "\n",
    "Stability indices help assess avalanche risk. Common ones include:\n",
    "- **Skier Stability Index (SK38)**: Probability of skier-triggered avalanche\n",
    "- **Stability Index**: General stability metric\n",
    "- **Rutschblock Score**: Field test equivalent\n",
    "\n",
    "**Note**: These calculations depend on specific formulas and may require xsnow extensions or custom implementation. Let's explore what's available:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if xsnow has built-in stability index functions\n",
    "# Check for extension methods\n",
    "extension_methods = [attr for attr in dir(ds) if not attr.startswith('_') and \n",
    "                    ('stability' in attr.lower() or 'hazard' in attr.lower() or \n",
    "                     'sk38' in attr.lower() or 'crack' in attr.lower())]\n",
    "\n",
    "if extension_methods:\n",
    "# Example: Simple stability proxy based on density gradient\n",
    "# Compute density gradient (change in density with depth)\n",
    "# Large gradients can indicate weak layers\n",
    "density_gradient = ds['density'].diff(dim='layer')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Temperature Gradient Analysis\n",
    "\n",
    "Temperature gradients are important for understanding metamorphism and weak layer formation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature gradient = change in temperature per unit depth\n",
    "# Large gradients can lead to faceting (weak layer formation)\n",
    "\n",
    "# Compute gradient using z coordinate\n",
    "temp_gradient = ds['temperature'].diff(dim='layer') / ds.coords['z'].diff(dim='layer')\n",
    "\n",
    "# Or use the temperature_gradient if already computed\n",
    "if 'temperature_gradient' in ds.data_vars:\n",
    "    tg = ds['temperature_gradient']\n",
    "    \n",
    "    # Find layers with high gradients (> 10 K/m often indicates faceting)\n",
    "    high_gradient = tg > 10  # K/m\n",
    "else:\n",
    "    Temperature gradient analysis:\n",
    "    \n",
    "    # Compute gradient\n",
    "    temp_gradient = ds['temperature'].diff(dim='layer') / ds.coords['z'].diff(dim='layer')\n",
    "    \n",
    "    # Or use pre-computed gradient\n",
    "    if 'temperature_gradient' in ds.data_vars:\n",
    "        tg = ds['temperature_gradient']\n",
    "    \n",
    "    # Find high-gradient layers (faceting conditions)\n",
    "    high_gradient = tg > 10  # K/m threshold\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Hazard Chart Calculations\n",
    "\n",
    "Hazard charts plot stability indices against depth. xsnow may have extensions for this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for hazard chart extension\n",
    "# Look for hazard-related methods\n",
    "if hasattr(ds, 'compute_hazard_chart') or hasattr(ds, 'hazard_chart'):\n",
    "    # Example usage would be:\n",
    "    # hc = ds.compute_hazard_chart()\n",
    "\n",
    "# Manual example: Create a simple stability-depth plot\n",
    "# Simple proxy: use inverse density as stability proxy\n",
    "# (lower density = potentially weaker, but this is simplified!)\n",
    "profile = ds.isel(location=0, time=-1, slope=0, realization=0)  # Last time step\n",
    "\n",
    "if 'z' in profile.coords:\n",
    "    depth = -profile.coords['z'].values\n",
    "    density = profile['density'].values\n",
    "    \n",
    "    # Simple stability proxy (NOT a real stability index!)\n",
    "    stability_proxy = 1.0 / (density + 1.0)  # Avoid division by zero\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 10))\n",
    "    ax.plot(stability_proxy, depth, 'b-', linewidth=2)\n",
    "    ax.set_xlabel('Stability Proxy (1/density)', fontsize=12)\n",
    "    ax.set_ylabel('Depth (m)', fontsize=12)\n",
    "    ax.set_title('Simple Stability-Depth Profile\\n(Example - Not Real Stability Index)', \n",
    "                fontsize=12)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Critical Crack Length\n",
    "\n",
    "Critical crack length is an advanced metric for assessing avalanche propagation potential:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for critical crack length method\n",
    "if hasattr(ds, 'compute_critical_crack_length'):\n",
    "    # Example: ccl = ds.compute_critical_crack_length()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Comparing Multiple Locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_locations = ds.dims.get('location', 0)\n",
    "\n",
    "if n_locations > 1:\n",
    "    # Compare mean density across locations\n",
    "    if 'density' in ds.data_vars:\n",
    "        mean_density_by_location = ds['density'].mean(dim=['time', 'layer'])\n",
    "        \n",
    "        for i, loc in enumerate(ds.coords['location'].values):\n",
    "    \n",
    "    # Compare snow height evolution\n",
    "    if 'HS' in ds.data_vars:\n",
    "        for i, loc in enumerate(ds.coords['location'].values):\n",
    "            hs_loc = ds['HS'].isel(location=i, slope=0, realization=0)\n",
    "else:\n",
    "    Comparing multiple locations:\n",
    "    \n",
    "    # Load multiple files\n",
    "    ds = xsnow.read(['data/station1.pro', 'data/station2.pro'])\n",
    "    \n",
    "    # Compare statistics\n",
    "    mean_density = ds['density'].mean(dim=['time', 'layer'])\n",
    "    \n",
    "    # Compare time series\n",
    "    for loc in ds.coords['location']:\n",
    "        hs = ds['HS'].sel(location=loc)\n",
    "        # Plot or analyze\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Advanced Temporal Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample to daily (if data is hourly)\n",
    "# This averages hourly data to daily\n",
    "try:\n",
    "    ds_daily = ds.resample(time='1D').mean()\n",
    "except:\n",
    "\n",
    "# Rolling window statistics\n",
    "if 'HS' in ds.data_vars:\n",
    "    hs_series = ds['HS'].isel(location=0, slope=0, realization=0)\n",
    "    \n",
    "    # 7-day rolling average\n",
    "    try:\n",
    "        hs_7day = hs_series.rolling(time=7, center=True).mean()\n",
    "    except:\n",
    "    \n",
    "    # Rate of change\n",
    "    hs_rate = hs_series.diff(dim='time')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Using xsnow Extensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what extensions/methods are available\n",
    "methods = [m for m in dir(ds) if not m.startswith('_') and callable(getattr(ds, m, None))]\n",
    "\n",
    "# Filter for potentially interesting methods\n",
    "interesting = [m for m in methods if any(keyword in m.lower() for keyword in \n",
    "                                        ['compute', 'calculate', 'hazard', 'stability', \n",
    "                                         'crack', 'classify', 'mask'])]\n",
    "\n",
    "if interesting:\n",
    "    for m in interesting[:10]:  # Show first 10\n",
    "else:\n",
    "    xsnow extensions:\n",
    "    \n",
    "    # Extensions add methods to xsnowDataset\n",
    "    # Common extensions include:\n",
    "    # - Classification (mask_by_criteria, etc.)\n",
    "    # - Hazard charts\n",
    "    # - Stability indices\n",
    "    # - Critical crack length\n",
    "    \n",
    "    # Check xsnow docs for:\n",
    "    # - How to import extensions\n",
    "    # - Available extension methods\n",
    "    # - How to create custom extensions (see notebook 06)\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Ensemble Analysis\n",
    "\n",
    "If you have multiple realizations (ensemble runs), analyze uncertainty:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_realizations = ds.dims.get('realization', 0)\n",
    "\n",
    "if n_realizations > 1:\n",
    "    \n",
    "    if 'HS' in ds.data_vars:\n",
    "        # Compute statistics across realizations\n",
    "        hs_mean = ds['HS'].mean(dim='realization')\n",
    "        hs_std = ds['HS'].std(dim='realization')\n",
    "        hs_min = ds['HS'].min(dim='realization')\n",
    "        hs_max = ds['HS'].max(dim='realization')\n",
    "        \n",
    "else:\n",
    "    Ensemble analysis:\n",
    "    \n",
    "    # Load multiple realizations\n",
    "    ds = xsnow.read(['run1.pro', 'run2.pro', 'run3.pro'])\n",
    "    # Or ensure realization dimension has multiple values\n",
    "    \n",
    "    # Statistics across ensemble\n",
    "    mean = ds['HS'].mean(dim='realization')\n",
    "    std = ds['HS'].std(dim='realization')\n",
    "    min_val = ds['HS'].min(dim='realization')\n",
    "    max_val = ds['HS'].max(dim='realization')\n",
    "    \n",
    "    # Plot with uncertainty bands\n",
    "    # plt.fill_between(times, min_val, max_val, alpha=0.3)\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "\u2705 **What we learned:**\n",
    "\n",
    "1. **Stability indices**: Methods for assessing avalanche risk (may require extensions)\n",
    "2. **Temperature gradients**: Important for understanding weak layer formation\n",
    "3. **Hazard charts**: Visualizing stability vs depth\n",
    "4. **Critical crack length**: Advanced propagation metric\n",
    "5. **Multi-location comparison**: Analyzing spatial patterns\n",
    "6. **Temporal analysis**: Resampling, rolling windows, rates of change\n",
    "7. **Extensions**: Using xsnow's extension system\n",
    "8. **Ensemble analysis**: Working with multiple realizations\n",
    "\n",
    "## Key Advanced Techniques\n",
    "\n",
    "- **Resampling**: `ds.resample(time='1D').mean()` for temporal aggregation\n",
    "- **Rolling windows**: `ds.rolling(time=7).mean()` for smoothing\n",
    "- **Ensemble stats**: `.mean(dim='realization')`, `.std(dim='realization')`\n",
    "- **Extensions**: Check xsnow docs for available extension methods\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Ready to work with your own data? Move on to:\n",
    "- **05_working_with_custom_data.ipynb**: Load and analyze your own files\n",
    "\n",
    "Or learn to extend xsnow:\n",
    "- **06_extending_xsnow.ipynb**: Create custom analysis functions\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. Compute temperature gradient and identify layers with gradients > 10 K/m\n",
    "2. Resample hourly data to daily and compare statistics\n",
    "3. If you have multiple locations, compare their mean density profiles\n",
    "4. Calculate a 7-day rolling average of snow height\n",
    "5. Check xsnow documentation for available extensions and try one\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}