{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04: Advanced Analysis\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Austfi/xsnowForPatrol/blob/main/notebooks/04_advanced_analysis.ipynb)\n",
    "\n",
    "This notebook covers advanced snowpack analysis techniques including stability indices, hazard calculations, and using xsnow extensions.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Stability indices and their calculation\n",
    "- Hazard chart calculations\n",
    "- Critical crack length\n",
    "- Comparing multiple locations and scenarios\n",
    "- Advanced temporal analysis\n",
    "- Using xsnow extensions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation (For Colab Users)\n",
    "\n",
    "If you're using Google Colab, run the cell below to install xsnow and dependencies. If you're running locally and have already installed xsnow, you can skip this cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%pip install -q numpy pandas xarray matplotlib seaborn dask netcdf4\n",
    "%pip install -q git+https://gitlab.com/avacollabra/postprocessing/xsnow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xsnow\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load xsnow's lightweight sample time series dataset\n",
    "print(\"Loading xsnow sample data for advanced analysis...\")\n",
    "print(\"Using xsnow.single_profile_timeseries()\")\n",
    "\n",
    "try:\n",
    "    ds = xsnow.single_profile_timeseries()\n",
    "    print(\"✅ Data loaded for advanced analysis\")\n",
    "    print(f\"Dataset dimensions: {dict(ds.dims)}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Error loading sample data: {e}\")\n",
    "    print(\"Make sure xsnow is properly installed:\")\n",
    "    print(\"  pip install git+https://gitlab.com/avacollabra/postprocessing/xsnow\")\n",
    "    ds = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Stability Indices\n",
    "\n",
    "Stability indices help assess avalanche risk. Common ones include:\n",
    "- **Skier Stability Index (SK38)**: Probability of skier-triggered avalanche\n",
    "- **Stability Index**: General stability metric\n",
    "- **Rutschblock Score**: Field test equivalent\n",
    "\n",
    "**Note**: These calculations depend on specific formulas and may require xsnow extensions or custom implementation. Let's explore what's available:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if xsnow has built-in stability index functions\n",
    "# Check for extension methods\n",
    "if ds is not None:\n",
    "    extension_methods = [attr for attr in dir(ds) if not attr.startswith('_') and \n",
    "                        ('stability' in attr.lower() or 'hazard' in attr.lower() or \n",
    "                         'sk38' in attr.lower() or 'crack' in attr.lower())]\n",
    "    \n",
    "    if extension_methods:\n",
    "        print(f\"Found extension methods: {extension_methods}\")\n",
    "        print(\"Check xsnow documentation for usage instructions.\")\n",
    "    else:\n",
    "        print(\"No built-in stability index methods found.\")\n",
    "        print(\"You may need to compute stability indices manually or use xsnow extensions.\")\n",
    "    \n",
    "    # Example: Simple stability proxy based on density gradient\n",
    "    # Compute density gradient (change in density with depth)\n",
    "    # Large gradients can indicate weak layers\n",
    "    if 'density' in ds.data_vars:\n",
    "        density_gradient = ds['density'].diff(dim='layer')\n",
    "        print(f\"\\nDensity gradient computed. Shape: {density_gradient.shape}\")\n",
    "        print(\"Large gradients may indicate weak layers.\")\n",
    "else:\n",
    "    print(\"Dataset not loaded. Load data first.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Temperature Gradient Analysis\n",
    "\n",
    "Temperature gradients are important for understanding metamorphism and weak layer formation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature gradient = change in temperature per unit depth\n",
    "# Large gradients can lead to faceting (weak layer formation)\n",
    "\n",
    "if ds is not None and 'temperature' in ds.data_vars and 'z' in ds.coords:\n",
    "    # Compute gradient using z coordinate\n",
    "    temp_diff = ds['temperature'].diff(dim='layer')\n",
    "    z_diff = ds.coords['z'].diff(dim='layer')\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    temp_gradient = temp_diff / z_diff.where(z_diff != 0, np.nan)\n",
    "    \n",
    "    # Or use the temperature_gradient if already computed\n",
    "    if 'temperature_gradient' in ds.data_vars:\n",
    "        tg = ds['temperature_gradient']\n",
    "        print(\"Using pre-computed temperature gradient\")\n",
    "    else:\n",
    "        tg = temp_gradient\n",
    "        print(\"Computed temperature gradient from temperature and z\")\n",
    "    \n",
    "    # Find layers with high gradients (> 10 K/m often indicates faceting)\n",
    "    high_gradient = tg > 10  # K/m\n",
    "    n_high_gradient = high_gradient.sum().values\n",
    "    \n",
    "    print(f\"Found {n_high_gradient} layers with temperature gradient > 10 K/m\")\n",
    "    print(\"High gradients may indicate faceting conditions (weak layer formation)\")\n",
    "else:\n",
    "    print(\"\"\"\n",
    "    Temperature gradient analysis:\n",
    "    \n",
    "    # Compute gradient\n",
    "    temp_gradient = ds['temperature'].diff(dim='layer') / ds.coords['z'].diff(dim='layer')\n",
    "    \n",
    "    # Or use pre-computed gradient\n",
    "    if 'temperature_gradient' in ds.data_vars:\n",
    "        tg = ds['temperature_gradient']\n",
    "    \n",
    "    # Find high-gradient layers (faceting conditions)\n",
    "    high_gradient = tg > 10  # K/m threshold\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Hazard Chart Calculations\n",
    "\n",
    "Hazard charts plot stability indices against depth. xsnow may have extensions for this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for hazard chart extension\n",
    "# Look for hazard-related methods\n",
    "if ds is not None:\n",
    "    if hasattr(ds, 'compute_hazard_chart') or hasattr(ds, 'hazard_chart'):\n",
    "        print(\"Hazard chart extension found. Check xsnow documentation for usage.\")\n",
    "        # Example usage would be:\n",
    "        # hc = ds.compute_hazard_chart()\n",
    "    else:\n",
    "        print(\"No built-in hazard chart method. Creating manual example...\")\n",
    "    \n",
    "    # Manual example: Create a simple stability-depth plot\n",
    "    # Simple proxy: use inverse density as stability proxy\n",
    "    # (lower density = potentially weaker, but this is simplified!)\n",
    "    profile = ds.isel(location=0, time=-1, slope=0, realization=0)  # Last time step\n",
    "    \n",
    "    if 'z' in profile.coords and 'density' in profile.data_vars:\n",
    "        depth = -profile.coords['z'].values\n",
    "        density = profile['density'].values\n",
    "        \n",
    "        # Simple stability proxy (NOT a real stability index!)\n",
    "        stability_proxy = 1.0 / (density + 1.0)  # Avoid division by zero\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(8, 10))\n",
    "        ax.plot(stability_proxy, depth, 'b-', linewidth=2)\n",
    "        ax.set_xlabel('Stability Proxy (1/density)', fontsize=12)\n",
    "        ax.set_ylabel('Depth (m)', fontsize=12)\n",
    "        ax.set_title('Simple Stability-Depth Profile\\n(Example - Not Real Stability Index)', \n",
    "                    fontsize=12)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Required variables (z, density) not available for stability plot\")\n",
    "else:\n",
    "    print(\"Dataset not loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Critical Crack Length\n",
    "\n",
    "Critical crack length is an advanced metric for assessing avalanche propagation potential:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for critical crack length method\n",
    "if ds is not None:\n",
    "    if hasattr(ds, 'compute_critical_crack_length'):\n",
    "        print(\"Critical crack length method found.\")\n",
    "        # Example: ccl = ds.compute_critical_crack_length()\n",
    "    else:\n",
    "        print(\"No built-in critical crack length method.\")\n",
    "        print(\"This is an advanced metric that may require xsnow extensions or custom implementation.\")\n",
    "        print(\"Check xsnow documentation for available extensions.\")\n",
    "else:\n",
    "    print(\"Dataset not loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Comparing Multiple Locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ds is not None:\n",
    "    n_locations = ds.dims.get('location', 0)\n",
    "    \n",
    "    if n_locations > 1:\n",
    "        print(f\"Comparing {n_locations} locations:\")\n",
    "        \n",
    "        # Compare mean density across locations\n",
    "        if 'density' in ds.data_vars:\n",
    "            mean_density_by_location = ds['density'].mean(dim=['time', 'layer'])\n",
    "            print(\"\\nMean density by location:\")\n",
    "            for i, loc in enumerate(ds.coords['location'].values):\n",
    "                mean_dens = mean_density_by_location.isel(location=i).values\n",
    "                print(f\"  {loc}: {mean_dens:.1f} kg/m³\")\n",
    "        \n",
    "        # Compare snow height evolution\n",
    "        if 'HS' in ds.data_vars:\n",
    "            print(\"\\nSnow height by location (last time step):\")\n",
    "            for i, loc in enumerate(ds.coords['location'].values):\n",
    "                hs_loc = ds['HS'].isel(location=i, slope=0, realization=0, time=-1)\n",
    "                print(f\"  {loc}: {hs_loc.values:.2f} m\")\n",
    "    else:\n",
    "        print(\"Only one location in dataset. To compare multiple locations:\")\n",
    "        print(\"  ds = xsnow.read(['data/station1.pro', 'data/station2.pro'])\")\n",
    "else:\n",
    "    print(\"\"\"\n",
    "    Comparing multiple locations:\n",
    "    \n",
    "    # Load multiple files\n",
    "    ds = xsnow.read(['data/station1.pro', 'data/station2.pro'])\n",
    "    \n",
    "    # Compare statistics\n",
    "    mean_density = ds['density'].mean(dim=['time', 'layer'])\n",
    "    \n",
    "    # Compare time series\n",
    "    for loc in ds.coords['location']:\n",
    "        hs = ds['HS'].sel(location=loc)\n",
    "        # Plot or analyze\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Advanced Temporal Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample to daily (if data is hourly)\n",
    "# This averages hourly data to daily\n",
    "if ds is not None:\n",
    "    try:\n",
    "        ds_daily = ds.resample(time='1D').mean()\n",
    "        print(f\"Resampled to daily: {dict(ds_daily.dims)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not resample (may already be daily or different frequency): {e}\")\n",
    "    \n",
    "    # Rolling window statistics\n",
    "    if 'HS' in ds.data_vars:\n",
    "        hs_series = ds['HS'].isel(location=0, slope=0, realization=0)\n",
    "        \n",
    "        # 7-day rolling average\n",
    "        try:\n",
    "            hs_7day = hs_series.rolling(time=7, center=True).mean()\n",
    "            print(\"7-day rolling average computed successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not compute rolling average: {e}\")\n",
    "        \n",
    "        # Rate of change\n",
    "        hs_rate = hs_series.diff(dim='time')\n",
    "        print(f\"Rate of change computed. Mean: {hs_rate.mean().values:.4f} m/time_step\")\n",
    "else:\n",
    "    print(\"Dataset not loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Using xsnow Extensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what extensions/methods are available\n",
    "methods = [m for m in dir(ds) if not m.startswith('_') and callable(getattr(ds, m, None))]\n",
    "\n",
    "# Filter for potentially interesting methods\n",
    "interesting = [m for m in methods if any(keyword in m.lower() for keyword in \n",
    "                                        ['compute', 'calculate', 'hazard', 'stability', \n",
    "                                         'crack', 'classify', 'mask'])]\n",
    "\n",
    "if interesting:\n",
    "    for m in interesting[:10]:  # Show first 10\n",
    "else:\n",
    "    xsnow extensions:\n",
    "    \n",
    "    # Extensions add methods to xsnowDataset\n",
    "    # Common extensions include:\n",
    "    # - Classification (mask_by_criteria, etc.)\n",
    "    # - Hazard charts\n",
    "    # - Stability indices\n",
    "    # - Critical crack length\n",
    "    \n",
    "    # Check xsnow docs for:\n",
    "    # - How to import extensions\n",
    "    # - Available extension methods\n",
    "    # - How to create custom extensions (see notebook 06)\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Ensemble Analysis\n",
    "\n",
    "If you have multiple realizations (ensemble runs), analyze uncertainty:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_realizations = ds.dims.get('realization', 0)\n",
    "\n",
    "if n_realizations > 1:\n",
    "    \n",
    "    if 'HS' in ds.data_vars:\n",
    "        # Compute statistics across realizations\n",
    "        hs_mean = ds['HS'].mean(dim='realization')\n",
    "        hs_std = ds['HS'].std(dim='realization')\n",
    "        hs_min = ds['HS'].min(dim='realization')\n",
    "        hs_max = ds['HS'].max(dim='realization')\n",
    "        \n",
    "else:\n",
    "    Ensemble analysis:\n",
    "    \n",
    "    # Load multiple realizations\n",
    "    ds = xsnow.read(['run1.pro', 'run2.pro', 'run3.pro'])\n",
    "    # Or ensure realization dimension has multiple values\n",
    "    \n",
    "    # Statistics across ensemble\n",
    "    mean = ds['HS'].mean(dim='realization')\n",
    "    std = ds['HS'].std(dim='realization')\n",
    "    min_val = ds['HS'].min(dim='realization')\n",
    "    max_val = ds['HS'].max(dim='realization')\n",
    "    \n",
    "    # Plot with uncertainty bands\n",
    "    # plt.fill_between(times, min_val, max_val, alpha=0.3)\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "✅ **What we learned:**\n",
    "\n",
    "1. **Stability indices**: Methods for assessing avalanche risk (may require extensions)\n",
    "2. **Temperature gradients**: Important for understanding weak layer formation\n",
    "3. **Hazard charts**: Visualizing stability vs depth\n",
    "4. **Critical crack length**: Advanced propagation metric\n",
    "5. **Multi-location comparison**: Analyzing spatial patterns\n",
    "6. **Temporal analysis**: Resampling, rolling windows, rates of change\n",
    "7. **Extensions**: Using xsnow's extension system\n",
    "8. **Ensemble analysis**: Working with multiple realizations\n",
    "\n",
    "## Key Advanced Techniques\n",
    "\n",
    "- **Resampling**: `ds.resample(time='1D').mean()` for temporal aggregation\n",
    "- **Rolling windows**: `ds.rolling(time=7).mean()` for smoothing\n",
    "- **Ensemble stats**: `.mean(dim='realization')`, `.std(dim='realization')`\n",
    "- **Extensions**: Check xsnow docs for available extension methods\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Ready to work with your own data? Move on to:\n",
    "- **05_working_with_custom_data.ipynb**: Load and analyze your own files\n",
    "\n",
    "Or learn to extend xsnow:\n",
    "- **06_extending_xsnow.ipynb**: Create custom analysis functions\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. Compute temperature gradient and identify layers with gradients > 10 K/m\n",
    "2. Resample hourly data to daily and compare statistics\n",
    "3. If you have multiple locations, compare their mean density profiles\n",
    "4. Calculate a 7-day rolling average of snow height\n",
    "5. Check xsnow documentation for available extensions and try one\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
