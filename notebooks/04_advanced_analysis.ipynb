{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04: Advanced Analysis\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Austfi/xsnowForPatrol/blob/main/notebooks/04_advanced_analysis.ipynb)\n",
    "\n",
    "This notebook covers advanced snowpack analysis techniques including stability indices, hazard calculations, and using xsnow extensions.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Stability indices and their calculation\n",
    "- Hazard chart calculations\n",
    "- Critical crack length\n",
    "- Comparing multiple locations and scenarios\n",
    "- Advanced temporal analysis\n",
    "- Using xsnow extensions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation (For Colab Users)\n",
    "\n",
    "If you're using Google Colab, run the cell below to install xsnow and dependencies. If you're running locally and have already installed xsnow, you can skip this cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%pip install -q numpy pandas xarray matplotlib seaborn dask netcdf4\n",
    "%pip install -q git+https://gitlab.com/avacollabra/postprocessing/xsnow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xsnow\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load xsnow's lightweight sample time series dataset\n",
    "print(\"Loading xsnow sample data for advanced analysis...\")\n",
    "print(\"Using xsnow.single_profile_timeseries()\")\n",
    "\n",
    "try:\n",
    "    ds = xsnow.single_profile_timeseries()\n",
    "    print(\"\u2705 Data loaded for advanced analysis\")\n",
    "    print(f\"Dataset dimensions: {dict(ds.dims)}\")\n",
    "except Exception as e:\n",
    "    print(f\"\u26a0\ufe0f Error loading sample data: {e}\")\n",
    "    print(\"Make sure xsnow is properly installed:\")\n",
    "    print(\"  pip install git+https://gitlab.com/avacollabra/postprocessing/xsnow\")\n",
    "    ds = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Stability Indices\n",
    "\n",
    "Stability indices help assess avalanche risk. Common ones include:\n",
    "- **Skier Stability Index (SK38)**: Probability of skier-triggered avalanche\n",
    "- **Stability Index**: General stability metric\n",
    "- **Rutschblock Score**: Field test equivalent\n",
    "\n",
    "**Note**: These calculations depend on specific formulas and may require xsnow extensions or custom implementation. Let's explore what's available:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if xsnow has built-in stability index functions\n",
    "# Check for extension methods\n",
    "print(\"Checking for xsnow extension methods...\")\n",
    "extension_methods = [attr for attr in dir(ds) if not attr.startswith('_') and \n",
    "                    ('stability' in attr.lower() or 'hazard' in attr.lower() or \n",
    "                     'sk38' in attr.lower() or 'crack' in attr.lower())]\n",
    "\n",
    "if extension_methods:\n",
    "    print(f\"Found extension methods: {extension_methods}\")\n",
    "# Example: Simple stability proxy based on density gradient\n",
    "# Compute density gradient (change in density with depth)\n",
    "# Large gradients can indicate weak layers\n",
    "density_gradient = ds['density'].diff(dim='layer')\n",
    "\n",
    "print(\"\\nDensity gradient (proxy for stability indicator):\")\n",
    "print(f\"Shape: {density_gradient.shape}\")\n",
    "print(\"Large negative gradients may indicate weak layers\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Temperature Gradient Analysis\n",
    "\n",
    "Temperature gradients are important for understanding metamorphism and weak layer formation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature gradient = change in temperature per unit depth\n",
    "# Large gradients can lead to faceting (weak layer formation)\n",
    "\n",
    "# Compute gradient using z coordinate\n",
    "temp_gradient = ds['temperature'].diff(dim='layer') / ds.coords['z'].diff(dim='layer')\n",
    "\n",
    "# Or use the temperature_gradient if already computed\n",
    "if 'temperature_gradient' in ds.data_vars:\n",
    "    print(\"\u2705 Temperature gradient already in dataset\")\n",
    "    tg = ds['temperature_gradient']\n",
    "    print(f\"Shape: {tg.shape}\")\n",
    "    print(f\"Units: {tg.attrs.get('units', 'K/m')}\")\n",
    "    \n",
    "    # Find layers with high gradients (> 10 K/m often indicates faceting)\n",
    "    high_gradient = tg > 10  # K/m\n",
    "    print(f\"\\nLayers with high gradient (> 10 K/m): {high_gradient.sum().values}\")\n",
    "else:\n",
    "    print(\"\"\"\n",
    "    Temperature gradient analysis:\n",
    "    \n",
    "    # Compute gradient\n",
    "    temp_gradient = ds['temperature'].diff(dim='layer') / ds.coords['z'].diff(dim='layer')\n",
    "    \n",
    "    # Or use pre-computed gradient\n",
    "    if 'temperature_gradient' in ds.data_vars:\n",
    "        tg = ds['temperature_gradient']\n",
    "    \n",
    "    # Find high-gradient layers (faceting conditions)\n",
    "    high_gradient = tg > 10  # K/m threshold\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Hazard Chart Calculations\n",
    "\n",
    "Hazard charts plot stability indices against depth. xsnow may have extensions for this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for hazard chart extension\n",
    "# Look for hazard-related methods\n",
    "if hasattr(ds, 'compute_hazard_chart') or hasattr(ds, 'hazard_chart'):\n",
    "    print(\"\u2705 Hazard chart extension available\")\n",
    "    # Example usage would be:\n",
    "    # hc = ds.compute_hazard_chart()\n",
    "\n",
    "# Manual example: Create a simple stability-depth plot\n",
    "# Simple proxy: use inverse density as stability proxy\n",
    "# (lower density = potentially weaker, but this is simplified!)\n",
    "profile = ds.isel(location=0, time=-1, slope=0, realization=0)  # Last time step\n",
    "\n",
    "if 'z' in profile.coords:\n",
    "    depth = -profile.coords['z'].values\n",
    "    density = profile['density'].values\n",
    "    \n",
    "    # Simple stability proxy (NOT a real stability index!)\n",
    "    stability_proxy = 1.0 / (density + 1.0)  # Avoid division by zero\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 10))\n",
    "    ax.plot(stability_proxy, depth, 'b-', linewidth=2)\n",
    "    ax.set_xlabel('Stability Proxy (1/density)', fontsize=12)\n",
    "    ax.set_ylabel('Depth (m)', fontsize=12)\n",
    "    ax.set_title('Simple Stability-Depth Profile\\n(Example - Not Real Stability Index)', \n",
    "                fontsize=12)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nNote: This is a simplified example. Real hazard charts use\")\n",
    "    print(\"proper stability indices (SK38, etc.) from validated formulas.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Critical Crack Length\n",
    "\n",
    "Critical crack length is an advanced metric for assessing avalanche propagation potential:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for critical crack length method\n",
    "if hasattr(ds, 'compute_critical_crack_length'):\n",
    "    print(\"\u2705 Critical crack length method available\")\n",
    "    # Example: ccl = ds.compute_critical_crack_length()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Comparing Multiple Locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_locations = ds.dims.get('location', 0)\n",
    "\n",
    "if n_locations > 1:\n",
    "    # Compare mean density across locations\n",
    "    if 'density' in ds.data_vars:\n",
    "        mean_density_by_location = ds['density'].mean(dim=['time', 'layer'])\n",
    "        \n",
    "        print(\"Mean density by location:\")\n",
    "        for i, loc in enumerate(ds.coords['location'].values):\n",
    "            print(f\"  {loc}: {mean_density_by_location.isel(location=i).values:.1f} kg/m\u00b3\")\n",
    "    \n",
    "    # Compare snow height evolution\n",
    "    if 'HS' in ds.data_vars:\n",
    "        print(\"\\nSnow height statistics by location:\")\n",
    "        for i, loc in enumerate(ds.coords['location'].values):\n",
    "            hs_loc = ds['HS'].isel(location=i, slope=0, realization=0)\n",
    "            print(f\"  {loc}:\")\n",
    "            print(f\"    Mean: {hs_loc.mean().values:.2f} m\")\n",
    "            print(f\"    Max: {hs_loc.max().values:.2f} m\")\n",
    "            print(f\"    Min: {hs_loc.min().values:.2f} m\")\n",
    "else:\n",
    "    print(\"\"\"\n",
    "    Comparing multiple locations:\n",
    "    \n",
    "    # Load multiple files\n",
    "    ds = xsnow.read(['data/station1.pro', 'data/station2.pro'])\n",
    "    \n",
    "    # Compare statistics\n",
    "    mean_density = ds['density'].mean(dim=['time', 'layer'])\n",
    "    \n",
    "    # Compare time series\n",
    "    for loc in ds.coords['location']:\n",
    "        hs = ds['HS'].sel(location=loc)\n",
    "        # Plot or analyze\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Advanced Temporal Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample to daily (if data is hourly)\n",
    "# This averages hourly data to daily\n",
    "try:\n",
    "    ds_daily = ds.resample(time='1D').mean()\n",
    "    print(\"\u2705 Resampled to daily frequency\")\n",
    "    print(f\"Original: {len(ds.coords['time'])} time steps\")\n",
    "    print(f\"Daily: {len(ds_daily.coords['time'])} time steps\")\n",
    "except:\n",
    "    print(\"Resampling not applicable (may already be daily or different frequency)\")\n",
    "\n",
    "# Rolling window statistics\n",
    "if 'HS' in ds.data_vars:\n",
    "    hs_series = ds['HS'].isel(location=0, slope=0, realization=0)\n",
    "    \n",
    "    # 7-day rolling average\n",
    "    try:\n",
    "        hs_7day = hs_series.rolling(time=7, center=True).mean()\n",
    "        print(\"\\n\u2705 Computed 7-day rolling average\")\n",
    "    except:\n",
    "        print(\"Rolling window requires sufficient time steps\")\n",
    "    \n",
    "    # Rate of change\n",
    "    hs_rate = hs_series.diff(dim='time')\n",
    "    print(f\"\\nSnow height change rate:\")\n",
    "    print(f\"  Mean: {hs_rate.mean().values:.4f} m per time step\")\n",
    "    print(f\"  Max increase: {hs_rate.max().values:.4f} m\")\n",
    "    print(f\"  Max decrease: {hs_rate.min().values:.4f} m\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Using xsnow Extensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what extensions/methods are available\n",
    "print(\"Available xsnowDataset methods:\")\n",
    "methods = [m for m in dir(ds) if not m.startswith('_') and callable(getattr(ds, m, None))]\n",
    "\n",
    "# Filter for potentially interesting methods\n",
    "interesting = [m for m in methods if any(keyword in m.lower() for keyword in \n",
    "                                        ['compute', 'calculate', 'hazard', 'stability', \n",
    "                                         'crack', 'classify', 'mask'])]\n",
    "\n",
    "if interesting:\n",
    "    print(\"\\nPotentially relevant methods:\")\n",
    "    for m in interesting[:10]:  # Show first 10\n",
    "        print(f\"  - {m}\")\n",
    "else:\n",
    "    print(\"\"\"\n",
    "    xsnow extensions:\n",
    "    \n",
    "    # Extensions add methods to xsnowDataset\n",
    "    # Common extensions include:\n",
    "    # - Classification (mask_by_criteria, etc.)\n",
    "    # - Hazard charts\n",
    "    # - Stability indices\n",
    "    # - Critical crack length\n",
    "    \n",
    "    # Check xsnow docs for:\n",
    "    # - How to import extensions\n",
    "    # - Available extension methods\n",
    "    # - How to create custom extensions (see notebook 06)\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Ensemble Analysis\n",
    "\n",
    "If you have multiple realizations (ensemble runs), analyze uncertainty:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_realizations = ds.dims.get('realization', 0)\n",
    "\n",
    "if n_realizations > 1:\n",
    "    print(f\"\u2705 Found {n_realizations} realizations (ensemble data)\")\n",
    "    \n",
    "    if 'HS' in ds.data_vars:\n",
    "        # Compute statistics across realizations\n",
    "        hs_mean = ds['HS'].mean(dim='realization')\n",
    "        hs_std = ds['HS'].std(dim='realization')\n",
    "        hs_min = ds['HS'].min(dim='realization')\n",
    "        hs_max = ds['HS'].max(dim='realization')\n",
    "        \n",
    "        print(\"\\nSnow height statistics across ensemble:\")\n",
    "        print(f\"  Mean: {hs_mean.mean().values:.2f} m\")\n",
    "        print(f\"  Std dev: {hs_std.mean().values:.2f} m\")\n",
    "        print(f\"  Range: {hs_min.min().values:.2f} to {hs_max.max().values:.2f} m\")\n",
    "else:\n",
    "    print(\"\"\"\n",
    "    Ensemble analysis:\n",
    "    \n",
    "    # Load multiple realizations\n",
    "    ds = xsnow.read(['run1.pro', 'run2.pro', 'run3.pro'])\n",
    "    # Or ensure realization dimension has multiple values\n",
    "    \n",
    "    # Statistics across ensemble\n",
    "    mean = ds['HS'].mean(dim='realization')\n",
    "    std = ds['HS'].std(dim='realization')\n",
    "    min_val = ds['HS'].min(dim='realization')\n",
    "    max_val = ds['HS'].max(dim='realization')\n",
    "    \n",
    "    # Plot with uncertainty bands\n",
    "    # plt.fill_between(times, min_val, max_val, alpha=0.3)\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "\u2705 **What we learned:**\n",
    "\n",
    "1. **Stability indices**: Methods for assessing avalanche risk (may require extensions)\n",
    "2. **Temperature gradients**: Important for understanding weak layer formation\n",
    "3. **Hazard charts**: Visualizing stability vs depth\n",
    "4. **Critical crack length**: Advanced propagation metric\n",
    "5. **Multi-location comparison**: Analyzing spatial patterns\n",
    "6. **Temporal analysis**: Resampling, rolling windows, rates of change\n",
    "7. **Extensions**: Using xsnow's extension system\n",
    "8. **Ensemble analysis**: Working with multiple realizations\n",
    "\n",
    "## Key Advanced Techniques\n",
    "\n",
    "- **Resampling**: `ds.resample(time='1D').mean()` for temporal aggregation\n",
    "- **Rolling windows**: `ds.rolling(time=7).mean()` for smoothing\n",
    "- **Ensemble stats**: `.mean(dim='realization')`, `.std(dim='realization')`\n",
    "- **Extensions**: Check xsnow docs for available extension methods\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Ready to work with your own data? Move on to:\n",
    "- **05_working_with_custom_data.ipynb**: Load and analyze your own files\n",
    "\n",
    "Or learn to extend xsnow:\n",
    "- **06_extending_xsnow.ipynb**: Create custom analysis functions\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. Compute temperature gradient and identify layers with gradients > 10 K/m\n",
    "2. Resample hourly data to daily and compare statistics\n",
    "3. If you have multiple locations, compare their mean density profiles\n",
    "4. Calculate a 7-day rolling average of snow height\n",
    "5. Check xsnow documentation for available extensions and try one\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}