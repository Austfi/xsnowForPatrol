{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version compatibility check\n",
    "\n",
    "This notebook compares the xsnow package installed in your environment with the documentation version it was written for.",
    " The helper below calls `scripts/check_docs_version.py` so you can confirm that the package and docs align before continuing.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "\n",
    "def _find_script() -> Path | None:\n",
    "    current = Path.cwd().resolve()\n",
    "    for candidate in [current, *current.parents]:\n",
    "        script = candidate / \"scripts\" / \"check_docs_version.py\"\n",
    "        if script.exists():\n",
    "            return script\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_docs_version() -> tuple[str | None, str | None]:\n",
    "    script_path = _find_script()\n",
    "    if script_path is None:\n",
    "        return None, \"scripts/check_docs_version.py was not found\"\n",
    "    try:\n",
    "        completed = subprocess.run(\n",
    "            [sys.executable, str(script_path)],\n",
    "            check=True,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "        )\n",
    "    except subprocess.CalledProcessError as exc:\n",
    "        output = (exc.stdout or \"\") + (exc.stderr or \"\")\n",
    "        return None, output.strip() or str(exc)\n",
    "    return completed.stdout.strip() or None, None\n",
    "\n",
    "\n",
    "docs_version, docs_error = get_docs_version()\n",
    "\n",
    "try:\n",
    "    import xsnow\n",
    "    package_version = xsnow.__version__\n",
    "except Exception as exc:  # pylint: disable=broad-except\n",
    "    xsnow = None  # type: ignore[assignment]\n",
    "    package_version = None\n",
    "    package_error = str(exc)\n",
    "else:\n",
    "    package_error = None\n",
    "\n",
    "print(f\"xsnow package version: {package_version if package_version else 'not installed'}\")\n",
    "if package_error and not package_version:\n",
    "    print(f\"Import error: {package_error}\")\n",
    "\n",
    "if docs_version:\n",
    "    print(f\"xsnow docs version: {docs_version}\")\n",
    "else:\n",
    "    message = \"xsnow docs version: unavailable\"\n",
    "    if docs_error:\n",
    "        message += f\" ({docs_error})\"\n",
    "    print(message)\n",
    "\n",
    "if docs_version and package_version and docs_version != package_version:\n",
    "    warnings.warn(\n",
    "        \"xsnow package version differs from the documentation version. \"\n",
    "        \"Consider aligning them before executing the notebook.\",\n",
    "        stacklevel=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02: Basic Operations and Analysis\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Austfi/xsnowForPatrol/blob/main/notebooks/02_basic_operations_and_analysis.ipynb)\n",
    "\n",
    "Now that you understand xsnow's data structure, let's learn how to work with the data: selecting, filtering, and performing basic analyses.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Selecting data by location, time, and layer\n",
    "- Filtering data with conditions\n",
    "- Computing profile-level summaries\n",
    "- Calculating snow water equivalent (SWE)\n",
    "- Identifying weak layers\n",
    "- Time series operations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation (For Colab Users)\n",
    "\n",
    "Set `INSTALL_XSNOW = True` in the next cell if you need to install xsnow. ",
    "When enabled you can pick `INSTALL_METHOD = \"pip\"` to install published packages or `INSTALL_METHOD = \"dev\"` to work from a local clone.",
    " The cell also installs the supporting scientific Python stack used throughout the course.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "INSTALL_XSNOW = False  # Set to True to install or update xsnow in this environment.\n",
    "INSTALL_METHOD = \"pip\"  # Choose \"pip\" for a package install, or \"dev\" for a developer clone.\n",
    "DEV_REPO_URL = \"https://gitlab.com/avacollabra/postprocessing/xsnow.git\"\n",
    "DEV_CLONE_DIR = Path.home() / \"xsnow-dev\"\n",
    "\n",
    "\n",
    "def _run(cmd: list[str]) -> None:\n",
    "    print(f\"$ {' '.join(cmd)}\")\n",
    "    subprocess.check_call(cmd)\n",
    "\n",
    "\n",
    "try:\n",
    "    import xsnow\n",
    "    print(f\"xsnow {xsnow.__version__} is already available.\")\n",
    "except Exception as exc:  # pylint: disable=broad-except\n",
    "    xsnow = None  # type: ignore[assignment]\n",
    "    print(f\"xsnow is not currently available: {exc}\")\n",
    "    if not INSTALL_XSNOW:\n",
    "        print(\"Set INSTALL_XSNOW = True and re-run this cell to install xsnow (pip or dev clone).\")\n",
    "    else:\n",
    "        try:\n",
    "            if INSTALL_METHOD == \"pip\":\n",
    "                _run([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", \"numpy\", \"pandas\", \"xarray\", \"matplotlib\", \"seaborn\", \"dask\", \"netcdf4\"])\n",
    "                _run([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", \"git+https://gitlab.com/avacollabra/postprocessing/xsnow\"])\n",
    "            elif INSTALL_METHOD == \"dev\":\n",
    "                if not DEV_CLONE_DIR.exists():\n",
    "                    _run([\"git\", \"clone\", DEV_REPO_URL, str(DEV_CLONE_DIR)])\n",
    "                _run([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", \"-e\", str(DEV_CLONE_DIR)])\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported INSTALL_METHOD: {INSTALL_METHOD}\")\n",
    "        except subprocess.CalledProcessError as install_error:\n",
    "            raise RuntimeError(\"xsnow installation command failed\") from install_error\n",
    "        import xsnow  # noqa: F401  # pylint: disable=import-outside-toplevel\n",
    "        print(f\"xsnow {xsnow.__version__} installed successfully.\")\n",
    "else:\n",
    "    INSTALL_XSNOW = INSTALL_XSNOW  # no-op so variable is defined for later cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Load Sample Data\n",
    "\n",
    "Let's load sample data to work with:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xsnow\n",
    "import numpy as np\n",
    "\n",
    "# Load sample data\n",
    "print(\"Loading sample data...\")\n",
    "try:\n",
    "    ds = xsnow.single_profile_timeseries()\n",
    "    print(\"\u2705 Data loaded!\")\n",
    "    print(f\"Dimensions: {dict(ds.dims)}\")\n",
    "except Exception as e:\n",
    "    print(f\"\u274c Error: {e}\")\n",
    "    print(\"Install: pip install git+https://gitlab.com/avacollabra/postprocessing/xsnow\")\n",
    "    ds = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Selecting Data\n",
    "\n",
    "You can select parts of your data in two ways:\n",
    "\n",
    "### Selecting by Label with `.sel()`\n",
    "\n",
    "Use `.sel()` when you know the label (like a date or location name):\n",
    "\n",
    "**What you'll see:** The code below selects data for a specific location and time. The result is a smaller dataset containing only the selected data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a specific location\n",
    "if len(ds.coords['location']) > 0:\n",
    "    location_name = ds.coords['location'].values[0]\n",
    "    ds_site = ds.sel(location=location_name)\n",
    "\n",
    "# Select a specific time (or time range)\n",
    "if len(ds.coords['time']) > 0:\n",
    "    # Get first and last time\n",
    "    times = ds.coords['time'].values\n",
    "    \n",
    "    # Select a single time\n",
    "    ds_single_time = ds.sel(time=times[0])\n",
    "    \n",
    "    # Select a time range using slice\n",
    "    ds_time_range = ds.sel(time=slice(times[0], times[9]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting by Index with `.isel()`\n",
    "\n",
    "Use `.isel()` when you want to select by position (first, second, etc.):\n",
    "\n",
    "**What you'll see:** These examples show how to select the first time step, first few time steps, surface layer, and multiple layers. The resulting datasets will have fewer dimensions than the original.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first time step\n",
    "ds_first = ds.isel(time=0)\n",
    "\n",
    "# Get first 5 time steps\n",
    "ds_first5 = ds.isel(time=slice(0, 5))\n",
    "\n",
    "# Get surface layer (layer 0)\n",
    "surface = ds.isel(layer=0)\n",
    "\n",
    "# Get multiple layers\n",
    "top_layers = ds.isel(layer=[0, 1, 2])  # Top 3 layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting by Depth (using 'z' coordinate)\n",
    "\n",
    "Remember the `z` coordinate? We can use it to select layers by depth:\n",
    "\n",
    "**What you'll see:** The code below filters for layers within 50 cm of the surface. The result will have fewer layers than the original dataset, containing only layers that meet the depth criteria.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select layers within 50 cm of surface (z between 0 and -0.5)\n",
    "# Note: z is negative downward, so we want z >= -0.5\n",
    "shallow = ds.where((ds.coords['z'] >= -0.5) & (ds.coords['z'] <= 0), drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Filtering Data with Conditions\n",
    "\n",
    "You can filter data based on conditions (e.g., \"show me only dense layers\"). This is done with `.where()`:\n",
    "\n",
    "**What you'll see:** The code below creates filtered datasets containing only layers that meet specific criteria (dense snow, cold temperatures). These filtered datasets will have fewer layers than the original.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find layers with density > 300 kg/m\u00b3 (dense snow)\n",
    "dense_mask = ds['density'] > 300\n",
    "dense_layers = ds.where(dense_mask, drop=True)\n",
    "\n",
    "\n",
    "# Find cold layers (temperature < -10\u00b0C)\n",
    "if 'temperature' in ds.data_vars:\n",
    "    cold_mask = ds['temperature'] < -10\n",
    "    cold_layers = ds.where(cold_mask, drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Computing Profile-Level Summaries\n",
    "\n",
    "Often you want to summarize layer-level data into a single value per profile. For example, \"what's the average density in each profile?\"\n",
    "\n",
    "**What you'll see:** The code below computes mean, max, and min density across all layers for each profile. The result is a new variable with the `layer` dimension removed - it's now a profile-level variable (one value per profile per time step).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean density across all layers for each profile\n",
    "mean_density = ds['density'].mean(dim='layer')\n",
    "\n",
    "# Other useful aggregations\n",
    "max_density = ds['density'].max(dim='layer')  # Maximum density in profile\n",
    "min_density = ds['density'].min(dim='layer')   # Minimum density in profile\n",
    "std_density = ds['density'].std(dim='layer')   # Standard deviation\n",
    "\n",
    "\n",
    "# Add as new variable to dataset\n",
    "ds = ds.assign(mean_density=mean_density)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Calculating Snow Water Equivalent (SWE)\n",
    "\n",
    "**Snow Water Equivalent (SWE)** is a critical metric: it tells you how much water is in the snowpack. SWE = density \u00d7 thickness, summed over all layers.\n",
    "\n",
    "### Understanding SWE\n",
    "\n",
    "- **Why it matters**: SWE tells you the actual water content, not just snow depth\n",
    "- **Units**: Typically mm or m of water\n",
    "- **Calculation**: For each layer: density (kg/m\u00b3) \u00d7 thickness (m) = water equivalent (kg/m\u00b2 or mm)\n",
    "\n",
    "Let's compute it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: If we have layer thickness directly\n",
    "if 'thickness' in ds.data_vars:\n",
    "    # SWE = sum(density * thickness) over all layers\n",
    "    swe = (ds['density'] * ds['thickness']).sum(dim='layer') / 1000.0  # Convert to m\n",
    "    print(f\"SWE calculated from thickness: {swe.values[0]:.3f} m (first profile)\")\n",
    "    ds = ds.assign(SWE=swe)\n",
    "\n",
    "# Method 2: Compute thickness from 'z' coordinate (depth)\n",
    "elif 'z' in ds.coords and 'density' in ds.data_vars:\n",
    "    # Layer thickness = difference in z between adjacent layers\n",
    "    # For each layer, thickness = |z[i] - z[i+1]|, except last layer\n",
    "    z = ds.coords['z']\n",
    "    \n",
    "    # Compute thickness by differencing z (absolute value since z is negative)\n",
    "    z_diff = z.diff(dim='layer', label='upper')\n",
    "    thickness = -z_diff  # Negative because z decreases downward\n",
    "    \n",
    "    # For the last layer, estimate thickness from remaining depth\n",
    "    # This is a simplified approach - in practice, you'd need more sophisticated handling\n",
    "    if 'HS' in ds.data_vars:\n",
    "        # Use HS to estimate remaining thickness for last layer\n",
    "        total_thickness = -z.isel(layer=0)  # Depth of first layer\n",
    "        computed_thickness = thickness.sum(dim='layer', skipna=True)\n",
    "        last_layer_thickness = total_thickness - computed_thickness\n",
    "        \n",
    "        # Fill NaN values in thickness with estimated last layer thickness\n",
    "        thickness = thickness.fillna(last_layer_thickness)\n",
    "        \n",
    "        # Calculate SWE\n",
    "        swe = (ds['density'] * thickness).sum(dim='layer') / 1000.0  # Convert to m\n",
    "        print(f\"SWE calculated from z coordinate: {swe.values[0]:.3f} m (first profile)\")\n",
    "        ds = ds.assign(SWE=swe)\n",
    "    else:\n",
    "        print(\"Note: HS not available, using simplified thickness calculation\")\n",
    "        swe = (ds['density'] * thickness.fillna(0)).sum(dim='layer') / 1000.0\n",
    "        ds = ds.assign(SWE=swe)\n",
    "\n",
    "# Method 3: If SWE is already in the dataset\n",
    "if 'SWE' in ds.data_vars or 'swe' in ds.data_vars:\n",
    "    swe_var = ds['SWE'] if 'SWE' in ds.data_vars else ds['swe']\n",
    "    print(f\"SWE found in dataset: {swe_var.values[0]:.3f} m (first profile)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Identifying Weak Layers\n",
    "\n",
    "Weak layers are critical for avalanche forecasting. A weak layer is typically characterized by:\n",
    "- Low density\n",
    "- Specific grain types (e.g., faceted crystals)\n",
    "- Low strength/hardness\n",
    "\n",
    "Let's create a simple weak layer identifier:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weak layer criteria\n",
    "# This is a simplified example - real weak layer identification is more complex\n",
    "\n",
    "weak_mask = None\n",
    "\n",
    "if 'density' in ds.data_vars:\n",
    "    # Weak layers often have low density (< 150 kg/m\u00b3)\n",
    "    low_density = ds['density'] < 150\n",
    "    \n",
    "    if 'grain_type' in ds.data_vars:\n",
    "        # Some grain types indicate weak layers (this depends on your grain type coding)\n",
    "        # Example: grain_type == 4 might indicate faceted crystals\n",
    "        # Note: Check your data's grain type coding scheme!\n",
    "        # weak_grain = ds['grain_type'] == 4  # Example only\n",
    "        weak_mask = low_density  # Simplified: just use density for now\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Time Series Operations\n",
    "\n",
    "xsnow makes it easy to analyze how snowpack properties change over time.\n",
    "\n",
    "### Time-based Aggregations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean over time (average profile)\n",
    "if 'density' in ds.data_vars:\n",
    "    mean_density_over_time = ds['density'].mean(dim='time')\n",
    "\n",
    "# Compute time series of profile-level variables\n",
    "if 'HS' in ds.data_vars:\n",
    "    hs_series = ds['HS'].isel(location=0, slope=0, realization=0)\n",
    "\n",
    "# Compute change over time (difference between consecutive time steps)\n",
    "if 'HS' in ds.data_vars:\n",
    "    hs_change = ds['HS'].diff(dim='time')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Values as NumPy Arrays\n",
    "\n",
    "Sometimes you need raw NumPy arrays for integration with other libraries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get values as NumPy array\n",
    "density_array = ds['density'].values\n",
    "\n",
    "# Get values for a specific selection\n",
    "surface_density = ds['density'].sel(layer=0).values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "\u2705 **What we learned:**\n",
    "\n",
    "1. **Selecting data**: `.sel()` for labels, `.isel()` for positions\n",
    "2. **Filtering**: `.where()` with conditions to find specific layers/profiles\n",
    "3. **Aggregations**: `.mean()`, `.max()`, `.min()`, `.sum()` across dimensions\n",
    "4. **SWE calculation**: Sum of density \u00d7 thickness over layers\n",
    "5. **Weak layer identification**: Using conditions to find problematic layers\n",
    "6. **Time series**: Analyzing changes over time with `.diff()`, `.mean()`, etc.\n",
    "7. **NumPy integration**: `.values` to get raw arrays when needed\n",
    "\n",
    "## Key Operations Cheat Sheet\n",
    "\n",
    "```python\n",
    "# Selection\n",
    "ds.sel(location=\"VIR1A\", time=\"2024-02-01\")  # By label\n",
    "ds.isel(time=0, layer=0)                      # By position\n",
    "\n",
    "# Filtering\n",
    "ds.where(ds['density'] > 300, drop=True)      # Condition\n",
    "\n",
    "# Aggregations\n",
    "ds['density'].mean(dim='layer')               # Mean over layers\n",
    "ds['HS'].max(dim='time')                      # Max over time\n",
    "\n",
    "# Time operations\n",
    "ds['HS'].diff(dim='time')                     # Change over time\n",
    "ds.resample(time='1D').mean()                 # Resample\n",
    "\n",
    "# NumPy\n",
    "ds['density'].values                          # Get array\n",
    "```\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Ready to visualize your data? Move on to:\n",
    "- **03_visualization.ipynb**: Create plots and visualizations\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. Select data for a specific date and print the density profile\n",
    "2. Find all layers with temperature below -5\u00b0C\n",
    "3. Compute the mean density for the top 3 layers across all time steps\n",
    "4. Calculate how much the snow height changed between the first and last time step\n",
    "5. Identify profiles that have at least one layer with density < 100 kg/m\u00b3\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}