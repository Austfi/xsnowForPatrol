{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09: Performance and Storage\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Austfi/xsnowForPatrol/blob/main/notebooks/09_performance_and_storage.ipynb)\n",
    "\n",
    "This notebook covers performance optimization and storage formats for large xsnow datasets.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Data type optimization (float32 vs float64)\n",
    "- Memory management strategies\n",
    "- Zarr format for large datasets\n",
    "- Chunking and compression strategies\n",
    "\n",
    "> **Note**: This is a reference notebook covering performance topics. The main tutorial notebooks focus on core functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation (For Colab Users)\n",
    "\n",
    "If you're using Google Colab, run the cell below to install xsnow and dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q numpy pandas xarray matplotlib seaborn dask netcdf4 zarr\n",
    "%pip install -q git+https://gitlab.com/avacollabra/postprocessing/xsnow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xsnow\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import zarr\n",
    "\n",
    "# Load sample data\n",
    "ds = xsnow.single_profile_timeseries()\n",
    "print(\"✅ Data loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Type Optimization\n",
    "\n",
    "For large datasets, optimizing data types can significantly reduce memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check current data types\n",
    "print(\"Current data types:\")\n",
    "for var in list(ds.data_vars.keys())[:5]:\n",
    "    dtype = ds[var].dtype\n",
    "    size_mb = ds[var].nbytes / (1024**2)\n",
    "    print(f\"  {var}: {dtype} ({size_mb:.2f} MB)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Convert float64 to float32 (halves memory usage)\n",
    "density_vals = ds['density'].values\n",
    "density_min = density_vals.min()\n",
    "density_max = density_vals.max()\n",
    "\n",
    "print(f\"Original dtype: {ds['density'].dtype}\")\n",
    "print(f\"Value range: {density_min:.1f} to {density_max:.1f} kg/m³\")\n",
    "print(f\"Original size: {ds['density'].nbytes / (1024**2):.2f} MB\")\n",
    "\n",
    "# Convert to float32 if values fit\n",
    "if density_min >= np.finfo(np.float32).min and density_max <= np.finfo(np.float32).max:\n",
    "    density_float32 = ds['density'].astype('float32')\n",
    "    print(f\"Converted to float32: {density_float32.dtype}\")\n",
    "    print(f\"New size: {density_float32.nbytes / (1024**2):.2f} MB\")\n",
    "    print(f\"Memory saved: {(ds['density'].nbytes - density_float32.nbytes) / (1024**2):.2f} MB (50% reduction)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Zarr Format for Large Datasets\n",
    "\n",
    "Zarr is a format for storing chunked, compressed, N-dimensional arrays, ideal for large snowpack datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Save dataset to Zarr format\n",
    "zarr_path = \"snowpack_data.zarr\"\n",
    "\n",
    "try:\n",
    "    ds.to_zarr(\n",
    "        zarr_path,\n",
    "        encoding={\n",
    "            'density': {'compressor': zarr.Blosc(cname='zstd', clevel=3)},\n",
    "            'temperature': {'compressor': zarr.Blosc(cname='zstd', clevel=3)},\n",
    "        }\n",
    "    )\n",
    "    print(f\"✅ Saved to {zarr_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Note: Zarr save example (may need actual data): {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load from Zarr format\n",
    "try:\n",
    "    ds_zarr = xr.open_zarr(zarr_path)\n",
    "    print(f\"✅ Loaded from Zarr: {zarr_path}\")\n",
    "    print(f\"   Dimensions: {dict(ds_zarr.sizes)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Note: Zarr load example (file may not exist): {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "✅ **What we learned:**\n",
    "\n",
    "1. **Data type optimization**: Converting float64 to float32 to save memory\n",
    "2. **Zarr format**: Chunked, compressed storage for large datasets\n",
    "3. **Memory management**: Strategies for working with large datasets\n",
    "\n",
    "## Key Techniques\n",
    "\n",
    "- **`.astype()`**: Convert data types\n",
    "- **`.to_zarr()`**: Save to Zarr format\n",
    "- **`xr.open_zarr()`**: Load from Zarr format\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Return to the main tutorial notebooks to continue learning xsnow."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
