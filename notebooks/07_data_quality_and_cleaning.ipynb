{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 07: Data Quality and Cleaning\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Austfi/xsnowForPatrol/blob/main/notebooks/07_data_quality_and_cleaning.ipynb)\n",
        "\n",
        "This notebook covers comprehensive strategies for detecting, handling, and cleaning missing data in xsnow datasets.\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "- Detecting missing data (NaN values, outliers, invalid ranges)\n",
        "- Missing data handling strategies (interpolation, filling, dropping)\n",
        "- Data validation and quality checks\n",
        "- Cleaning pipelines for production use\n",
        "\n",
        "> **Note**: This is a reference notebook covering advanced data quality topics. The main tutorial notebooks focus on core functionality.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installation (For Colab Users)\n",
        "\n",
        "If you're using Google Colab, run the cell below to install xsnow and dependencies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q numpy pandas xarray matplotlib seaborn\n",
        "%pip install -q git+https://gitlab.com/avacollabra/postprocessing/xsnow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import xsnow\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load sample data\n",
        "ds = xsnow.single_profile_timeseries()\n",
        "print(\"✅ Data loaded successfully\")\n",
        "\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Detecting Missing Data\n",
        "\n",
        "Before cleaning data, you need to identify what's missing and where.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "missing_density = ds['density'].isnull()\n",
        "n_missing = missing_density.sum().values\n",
        "total = missing_density.size\n",
        "print(f\"Missing density values: {n_missing} out of {total} ({100*n_missing/total:.2f}%)\")\n",
        "\n",
        "# Check multiple variables\n",
        "print(\"\\nMissing data summary:\")\n",
        "for var in ['density', 'temperature', 'HS']:\n",
        "    if var in ds.data_vars:\n",
        "        n_miss = ds[var].isnull().sum().values\n",
        "        n_total = ds[var].size\n",
        "        pct = 100 * n_miss / n_total if n_total > 0 else 0\n",
        "        print(f\"  {var}: {n_miss} missing ({pct:.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2: Missing Data Handling Strategies\n",
        "\n",
        "### Strategy 1: Interpolation for Time Series\n",
        "\n",
        "For time series data, interpolation estimates missing values from neighboring time points.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Interpolate missing values in snow height time series\n",
        "hs_series = ds['HS'].isel(location=0, slope=0, realization=0)\n",
        "\n",
        "# Method 1: Linear interpolation (estimates between known points)\n",
        "hs_interpolated_linear = hs_series.interpolate_na(dim='time', method='linear')\n",
        "print(\"Linear interpolation: Estimates missing values from neighboring time points\")\n",
        "\n",
        "# Method 2: Polynomial interpolation (smoother curves)\n",
        "hs_interpolated_poly = hs_series.interpolate_na(dim='time', method='polynomial', order=2)\n",
        "print(\"Polynomial interpolation: Uses polynomial fit for smoother estimates\")\n",
        "\n",
        "# Compare results\n",
        "print(f\"\\nOriginal missing values: {hs_series.isnull().sum().values}\")\n",
        "print(f\"After linear interpolation: {hs_interpolated_linear.isnull().sum().values}\")\n",
        "print(f\"After polynomial interpolation: {hs_interpolated_poly.isnull().sum().values}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Strategy 2: Forward/Backward Fill for Profile Data\n",
        "\n",
        "For profile data (depth layers), use forward or backward fill to propagate values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Fill missing density values in a profile\n",
        "profile_density = ds['density'].isel(location=0, time=0, slope=0, realization=0)\n",
        "\n",
        "# Forward fill: Use previous layer's value (useful when surface layers are missing)\n",
        "density_ffill = profile_density.fillna(method='ffill', dim='layer')\n",
        "print(\"Forward fill: Missing values filled with previous layer's density\")\n",
        "\n",
        "# Backward fill: Use next layer's value (useful when deep layers are missing)\n",
        "density_bfill = profile_density.fillna(method='bfill', dim='layer')\n",
        "print(\"Backward fill: Missing values filled with next layer's density\")\n",
        "\n",
        "# Combined: Forward then backward (handles gaps in middle)\n",
        "density_combined = profile_density.fillna(method='ffill', dim='layer').fillna(method='bfill', dim='layer')\n",
        "print(\"Combined fill: Forward then backward fill\")\n",
        "\n",
        "# Check results\n",
        "print(f\"\\nOriginal missing: {profile_density.isnull().sum().values}\")\n",
        "print(f\"After forward fill: {density_ffill.isnull().sum().values}\")\n",
        "print(f\"After backward fill: {density_bfill.isnull().sum().values}\")\n",
        "print(f\"After combined fill: {density_combined.isnull().sum().values}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Strategy 3: Statistical Imputation\n",
        "\n",
        "Fill missing values with statistical measures (mean, median, mode).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Fill missing density with mean value\n",
        "mean_density = ds['density'].mean().values\n",
        "density_mean_filled = ds['density'].fillna(mean_density)\n",
        "print(f\"Mean fill: Missing values filled with overall mean ({mean_density:.1f} kg/m³)\")\n",
        "\n",
        "# Fill with median (more robust to outliers)\n",
        "median_density = ds['density'].median().values\n",
        "density_median_filled = ds['density'].fillna(median_density)\n",
        "print(f\"Median fill: Missing values filled with overall median ({median_density:.1f} kg/m³)\")\n",
        "\n",
        "# Fill with location-specific mean (better for multi-location data)\n",
        "density_location_mean = ds['density'].mean(dim=['time', 'layer', 'slope', 'realization'])\n",
        "density_location_filled = ds['density'].fillna(density_location_mean)\n",
        "print(\"Location-specific mean fill: Each location uses its own mean\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Strategy 4: Dropping Missing Data\n",
        "\n",
        "Sometimes it's better to remove data with missing values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Drop missing data with different strategies\n",
        "\n",
        "# Strategy 1: Drop any layer with missing density\n",
        "density_no_missing_layers = ds['density'].dropna(dim='layer')\n",
        "print(f\"Drop missing layers: {density_no_missing_layers.dims.get('layer', 'N/A')} layers remaining\")\n",
        "\n",
        "# Strategy 2: Drop entire profiles with ANY missing values (aggressive)\n",
        "profiles_clean = ds.dropna(dim='layer', how='any')\n",
        "print(f\"Drop profiles with any missing: {profiles_clean.dims.get('time', 'N/A')} profiles remaining\")\n",
        "\n",
        "# Strategy 3: Drop only if ALL values are missing (conservative)\n",
        "profiles_partial = ds.dropna(dim='layer', how='all')\n",
        "print(f\"Drop only fully-missing layers: {profiles_partial.dims.get('time', 'N/A')} profiles remaining\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 3: Data Validation\n",
        "\n",
        "Check for invalid values, outliers, and data quality issues.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for reasonable value ranges\n",
        "density_vals = ds['density'].values\n",
        "valid_vals = density_vals[~np.isnan(density_vals)]\n",
        "\n",
        "if len(valid_vals) > 0:\n",
        "    print(f\"Density range: {valid_vals.min():.1f} to {valid_vals.max():.1f} kg/m³\")\n",
        "    if valid_vals.min() < 0 or valid_vals.max() > 1000:\n",
        "        print(\"⚠️ Warning: Density values outside typical range (0-1000 kg/m³)\")\n",
        "    else:\n",
        "        print(\"✅ Density values in reasonable range\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "✅ **What we learned:**\n",
        "\n",
        "1. **Missing data detection**: Using `.isnull()` and `.sum()`\n",
        "2. **Interpolation**: For time series data\n",
        "3. **Forward/backward fill**: For profile data\n",
        "4. **Statistical imputation**: Using mean, median, etc.\n",
        "5. **Data validation**: Checking value ranges and quality\n",
        "6. **Dropping data**: When appropriate\n",
        "\n",
        "## Key Techniques\n",
        "\n",
        "- **`.isnull()`**: Detect missing values\n",
        "- **`.interpolate_na()`**: Interpolate missing values\n",
        "- **`.fillna()`**: Fill missing values with constants or methods\n",
        "- **`.dropna()`**: Remove missing values\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "Return to the main tutorial notebooks to continue learning xsnow.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
